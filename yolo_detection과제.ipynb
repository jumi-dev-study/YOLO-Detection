{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Kaggle API ÏÑ§Ï†ï\n",
        "!pip install -q kaggle\n",
        "\n",
        "# Kaggle API ÌÇ§ ÏóÖÎ°úÎìú (kaggle.json ÌååÏùº ÌïÑÏöî)\n",
        "from google.colab import files\n",
        "files.upload()  # kaggle.json ÏóÖÎ°úÎìú\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥Î°úÎìú\n",
        "!kaggle datasets download -d andrewmvd/road-sign-detection\n",
        "!unzip -q road-sign-detection.zip -d /content/road_sign_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "J7XcfNFaL7vC",
        "outputId": "5c50cc68-17dd-48bb-c032-a953e3856e69"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ee7cdff-a7bf-40e8-85f8-d87750a0fb6f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ee7cdff-a7bf-40e8-85f8-d87750a0fb6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/road-sign-detection\n",
            "License(s): CC0-1.0\n",
            "Downloading road-sign-detection.zip to /content\n",
            " 70% 153M/218M [00:00<00:00, 1.60GB/s]\n",
            "100% 218M/218M [00:00<00:00, 1.01GB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# ÌòÑÏû¨ Íµ¨Ï°∞ ÌôïÏù∏\n",
        "!ls -la /content/road_sign_data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYq5GlykNvXi",
        "outputId": "42bc482c-e745-42f5-ea3e-c3a1f810e5d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 76\n",
            "drwxr-xr-x 4 root root  4096 Jan  7 18:34 .\n",
            "drwxr-xr-x 1 root root  4096 Jan  7 18:34 ..\n",
            "drwxr-xr-x 2 root root 32768 Jan  7 18:34 annotations\n",
            "drwxr-xr-x 2 root root 32768 Jan  7 18:34 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/road_sign_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yjhlT7iN1Om",
        "outputId": "ddfd52e5-cdf9-4b7f-fc4e-31a10df806ec"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/road_sign_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ssaru/convert2Yolo.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6hzdCuZWsvc",
        "outputId": "78925558-7997-4d30-bb1c-b32f6be172f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'convert2Yolo'...\n",
            "remote: Enumerating objects: 215, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 215 (delta 38), reused 35 (delta 35), pack-reused 172 (from 1)\u001b[K\n",
            "Receiving objects: 100% (215/215), 994.67 KiB | 3.62 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd convert2Yolo/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m02rmelrW7UP",
        "outputId": "f4e5a9c0-6144-4271-ad34-0727f4d2e087"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/road_sign_data/convert2Yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5pqUXpFW997",
        "outputId": "ce392b64-956b-4582-a5aa-7a73d4a9d6f1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Pillow==7.2.0 (from -r requirements.txt (line 1))\n",
            "  Downloading Pillow-7.2.0.tar.gz (39.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.1/39.1 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cycler==0.10.0 (from -r requirements.txt (line 2))\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl.metadata (722 bytes)\n",
            "Collecting kiwisolver==1.0.1 (from -r requirements.txt (line 3))\n",
            "  Downloading kiwisolver-1.0.1.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting matplotlib==2.2.2 (from -r requirements.txt (line 4))\n",
            "  Downloading matplotlib-2.2.2.tar.gz (37.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m√ó\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python example.py \\\n",
        "    --datasets VOC \\\n",
        "    --img_path /content/road_sign_data/images \\\n",
        "    --label /content/road_sign_data/annotations \\\n",
        "    --convert_output_path /content/road_sign_data/converted_yolo_labels \\\n",
        "    --img_type '.png' \\\n",
        "    --manifest_path /content/road_sign_data \\\n",
        "    --cls_list_file ./voc.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxR13Ft9XBQy",
        "outputId": "e771550c-037e-42b2-f0bf-6ee7529918a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "VOC Parsing:   |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (877/877)  Complete\n",
            "\n",
            "\n",
            "YOLO Generating:|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (877/877)  Complete\n",
            "\n",
            "\n",
            "YOLO Saving:   |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% (877/877)  Complete\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Í≤ΩÎ°ú ÏÑ§Ï†ï\n",
        "base_path = Path('/content/road_sign_data')\n",
        "output_path = Path('/content/yolo_datasets')\n",
        "\n",
        "# YOLO ÎîîÎ†âÌÜ†Î¶¨ Íµ¨Ï°∞ ÏÉùÏÑ±\n",
        "# Ïù¥ÎØ∏ÏßÄ, ÎùºÎ≤®ÏùÑ Í∞ÅÍ∞Å ÌïôÏäµÏö©/ÌÖåÏä§Ìä∏Ïö©ÏúºÎ°ú ÎÇòÎàà Îí§ Ï†ÄÏû•Ìï† Ìè¥Îçî ÏÉùÏÑ±\n",
        "(output_path / 'images' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "(output_path / 'images' / 'test').mkdir(parents=True, exist_ok=True)\n",
        "(output_path / 'labels' / 'train').mkdir(parents=True, exist_ok=True)\n",
        "(output_path / 'labels' / 'test').mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "069BTRhOXi1M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# kaggleÏóê Í∏∞Ïû¨Îêú 4Í∞úÏùò ÌÅ¥ÎûòÏä§Î™Ö\n",
        "classes = ['trafficlight', 'stop', 'speedlimit', 'crosswalk']"
      ],
      "metadata": {
        "id": "fha0wsaHbxqM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_files = list(base_path.glob('images/*.png'))\n",
        "# print(image_files[:5])\n",
        "\n",
        "annotaion_files = list(base_path.glob('converted_yolo_labels/*.txt'))\n",
        "\n",
        "print(len(image_files), len(annotaion_files))"
      ],
      "metadata": {
        "id": "HsKHD3r_b-1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327ff81c-4cd3-4dac-88a2-c98ccadb5127"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "877 877\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "L9S1EVSne11R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, test_images, train_annots, test_annots = train_test_split(\n",
        "    image_files, annotaion_files, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(len(train_images), len(test_images))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3_Sgu7UfM2w",
        "outputId": "b5b881c9-7d32-4bc3-fd33-85bbdb68bf1b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "701 176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Data\n",
        "print('Processing training data..')\n",
        "\n",
        "for img_path, txt_path in zip(train_images, train_annots):\n",
        "  # Ïù¥ÎØ∏ÏßÄ Î≥µÏÇ¨\n",
        "  shutil.copy(img_path, output_path / 'images' / 'train' / img_path.name)\n",
        "  shutil.copy(txt_path, output_path / 'labels' / 'train' / txt_path.name)\n",
        "print('ÏôÑÎ£å!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re-n9Y-sf0ga",
        "outputId": "210261b3-51cb-440a-e1b6-ddd23f8d5ceb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing training data..\n",
            "ÏôÑÎ£å!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation Data\n",
        "print('Processing val data..')\n",
        "\n",
        "for img, txt in zip(test_images, test_annots):\n",
        "  shutil.copy(img, output_path / 'images' / 'test' / img.name)\n",
        "  shutil.copy(img, output_path / 'labels' / 'test' / txt.name)\n",
        "print('ÏôÑÎ£å!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itrn7FIkhHNv",
        "outputId": "d181c695-6ac5-466f-de15-683fddf6236c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing val data..\n",
            "ÏôÑÎ£å!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml"
      ],
      "metadata": {
        "id": "LUUCA5_tkhJL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# yaml ÌååÏùº ÏûëÏÑ±\n",
        "data_yaml = {\n",
        "    'path': '/content/yolo_datasets',\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'nc': len(classes),\n",
        "    'names': classes\n",
        "}"
      ],
      "metadata": {
        "id": "xnAZHRVQl_Ru"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/yolo_datasets/labels/val | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmQNRdT1zql9",
        "outputId": "070eb00b-195c-4c55-8290-f9cc0495d366"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "road104.txt\n",
            "road106.txt\n",
            "road110.txt\n",
            "road112.txt\n",
            "road113.txt\n",
            "road116.txt\n",
            "road11.txt\n",
            "road126.txt\n",
            "road135.txt\n",
            "road138.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/yolo_datasets/data.yaml', 'w') as f:\n",
        "  yaml.dump(data_yaml, f, sort_keys=False)\n",
        "\n",
        "# ÌôïÏù∏\n",
        "!cat /content/yolo_datasets/data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOfNX3LhmPtc",
        "outputId": "f52592a5-8d05-4ae0-c566-8aa9262fc014"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "path: /content/yolo_datasets\n",
            "train: images/train\n",
            "val: images/val\n",
            "nc: 4\n",
            "names:\n",
            "- trafficlight\n",
            "- stop\n",
            "- speedlimit\n",
            "- crosswalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8 ÏÑ§Ïπò\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Deuyk-L-mhnQ",
        "outputId": "c9c6883f-a740-4622-a331-7be04d6ec5fd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.249-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.249-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.249 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "X37MWHC6moMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "720f2f9c-315c-49b6-b0d7-43853ab42e7d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# ÌïôÏäµ\n",
        "results = model.train(\n",
        "  data='/content/yolo_datasets/data.yaml',\n",
        "  epochs=20,\n",
        "  batch=32,\n",
        "  imgsz=640,\n",
        "  device=0,\n",
        "  workers=2, # 2Í∞úÏùò Ïì∞Î†àÎìú\n",
        "  name='train_result'\n",
        ")"
      ],
      "metadata": {
        "id": "qKTaVZoimtQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d87eaa66-8106-4ae8-b341-70050ef9d466"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.249 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/yolo_datasets/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train_result2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolo_datasets/runs/detect/train_result2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2420.1¬±617.7 MB/s, size: 224.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_datasets/labels/train.cache... 561 images, 140 backgrounds, 561 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 701/701 1.5Mit/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road0.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road1.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road10.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road100.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road102.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road103.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road105.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road107.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road108.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road111.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road114.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road115.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road117.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road118.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road119.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road12.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road121.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road122.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road123.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road125.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road127.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road128.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road129.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road13.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road132.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road133.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road134.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road136.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road137.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road140.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road144.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road145.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road146.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road147.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road149.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road151.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road153.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road155.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road158.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road159.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road16.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road160.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road162.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road163.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road165.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road166.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road168.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road17.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road172.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road176.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road18.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road180.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road181.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road182.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road184.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road185.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road186.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road187.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road188.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road189.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road190.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road191.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road192.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road193.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road194.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road195.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road197.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road198.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road2.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road20.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road202.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road203.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road204.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road206.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road208.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road21.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road210.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road211.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road213.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road216.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road217.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road218.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road22.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road221.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road223.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road225.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road226.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road229.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road230.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road233.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road234.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road235.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road237.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road239.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road24.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road241.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road243.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road245.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road246.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road247.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road249.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road25.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road251.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road252.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road253.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road254.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road256.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road257.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road259.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road26.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road260.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road262.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road264.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road265.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road268.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road27.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road270.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road272.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road273.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road274.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road277.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road278.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road279.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road28.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road280.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road281.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road283.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road284.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road285.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road287.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road288.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road289.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road29.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road290.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road292.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road293.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road295.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road296.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road297.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road298.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road3.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road30.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road300.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road302.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road303.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road304.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road308.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road31.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road311.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road313.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road314.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road315.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road316.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road317.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road318.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road319.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road322.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road323.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road324.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road328.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road329.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road33.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road330.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road332.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road333.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road334.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road336.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road34.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road340.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road342.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road345.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road346.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road348.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road351.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road353.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road355.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road357.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road359.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road36.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road360.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road362.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road364.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road365.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road367.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road368.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road37.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road371.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road372.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road374.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road375.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road377.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road378.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road379.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road380.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road381.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road382.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road384.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road389.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road390.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road392.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road395.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road399.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road4.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road401.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road402.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road403.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road404.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road405.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road406.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road408.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road409.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road41.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road411.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road412.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road414.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road415.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road416.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road418.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road42.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road420.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road421.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road422.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road423.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road424.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road425.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road426.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road429.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road431.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road433.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road434.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road438.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road44.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road441.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road442.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road445.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road446.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road447.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road448.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road449.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road45.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road450.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road451.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road454.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road456.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road458.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road459.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road46.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road460.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road461.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road463.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road464.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road465.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road466.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road468.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road469.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road47.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road470.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road471.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road472.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road473.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road474.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road476.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road478.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road48.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road480.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road482.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road483.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road485.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road487.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road489.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road49.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road490.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road493.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road494.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road496.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road498.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road499.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road500.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road501.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road502.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road503.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road504.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road506.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road509.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road51.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road511.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road513.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road514.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road515.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road516.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road517.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road518.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road519.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road521.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road522.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road523.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road526.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road527.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road528.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road529.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road531.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road532.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road533.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road537.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road54.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road540.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road541.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road542.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road543.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road544.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road545.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road546.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road547.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road548.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road550.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road552.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road553.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road555.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road556.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road557.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road558.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road559.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road56.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road561.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road563.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road564.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road565.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road566.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road567.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road568.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road57.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road571.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road573.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road577.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road579.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road58.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road582.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road586.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road588.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road589.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road59.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road590.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road592.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road593.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road594.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road595.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road596.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road598.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road600.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road603.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road604.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road605.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road607.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road608.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road609.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road61.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road612.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road614.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road615.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road616.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road617.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road620.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road621.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road622.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road623.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road624.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road625.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road627.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road628.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road629.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road63.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road632.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road633.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road635.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road636.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road637.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road638.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road639.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road640.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road642.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road643.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road644.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road645.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road648.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road649.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road651.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road652.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road653.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road654.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road655.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road657.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road660.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road663.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road664.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road668.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road669.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road67.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road670.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road671.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road673.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road674.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road675.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road677.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road679.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road680.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road682.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road683.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road684.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road685.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road686.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road688.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road690.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road691.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road692.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road693.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road695.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road697.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road698.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road699.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road7.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road70.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road701.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road702.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road703.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road704.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road705.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road706.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road707.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road709.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road71.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road711.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road712.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road714.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road715.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road717.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road719.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road721.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road725.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road726.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road729.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road730.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road731.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road733.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road734.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road736.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road737.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road738.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road739.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road74.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road740.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road741.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road743.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road745.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road746.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road747.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road749.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road75.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road750.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road751.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road753.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road756.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road757.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road759.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road76.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road760.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road761.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road764.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road766.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road767.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road769.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road77.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road770.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road771.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road772.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road774.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road776.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road778.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road779.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road78.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road780.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road782.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road783.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road784.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road785.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road786.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road787.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road788.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road789.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road79.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road790.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road791.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road792.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road794.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road795.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road796.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road799.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road8.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road80.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road800.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road802.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road803.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road804.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road805.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road806.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road807.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road81.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road810.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road813.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road814.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road815.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road817.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road819.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road82.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road821.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road822.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road823.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road826.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road827.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road828.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road829.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road83.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road831.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road833.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road838.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road84.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road840.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road841.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road842.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road843.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road845.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road846.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road847.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road85.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road850.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road851.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road855.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road856.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road857.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road858.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road859.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road86.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road860.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road861.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road862.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road863.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road865.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road867.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road869.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road87.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road870.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road872.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road873.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road874.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road875.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road88.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road89.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road91.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road94.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road95.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road96.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/content/yolo_datasets/images/train/road97.png: ignoring corrupt image/label: could not convert string to float: 'None'\n",
            "WARNING ‚ö†Ô∏è Labels are missing or empty in /content/yolo_datasets/labels/train.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 494.4¬±223.4 MB/s, size: 212.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_datasets/labels/val.cache... 36 images, 140 backgrounds, 36 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 176/176 73.4Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road11.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road110.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road138.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road200.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road212.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road238.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road248.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road250.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road276.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road312.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road335.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road354.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road373.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road386.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road388.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road391.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road397.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road419.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road43.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road436.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road437.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road512.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road551.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road562.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road569.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road575.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road584.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road597.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road599.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road610.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road66.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road69.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road797.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road809.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road864.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road9.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "WARNING ‚ö†Ô∏è Labels are missing or empty in /content/yolo_datasets/labels/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "Plotting labels to /content/yolo_datasets/runs/detect/train_result2/labels.jpg... \n",
            "WARNING ‚ö†Ô∏è zero-size array to reduction operation maximum which has no identity\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolo_datasets/runs/detect/train_result2\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      3.91G          0      217.4          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.7s/it 8.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.5it/s 1.2s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      4.83G          0      217.5          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.4it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.9it/s 1.0s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      4.83G          0      213.3          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.0it/s 1.0s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20      4.83G          0      205.3          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.0it/s 1.0s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      4.83G          0      194.8          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.1it/s 1.0s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      4.83G          0      182.8          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.2it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.2it/s 1.3s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20      4.83G          0      173.1          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.3it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20      4.83G          0        167          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.1it/s 1.0s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20      4.83G          0      166.1          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.3it/s 1.3s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      4.83G          0      160.8          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.3it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      4.83G          0      157.6          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 1.1it/s 4.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.6it/s 1.1s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      4.83G          0      155.5          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.1it/s 2.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.0it/s 1.0s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20      4.83G          0      153.5          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.7it/s 1.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.2it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      4.83G          0      151.6          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.3it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20      4.83G          0      149.9          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.5it/s 2.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.2it/s 1.4s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      4.83G          0      148.7          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.4it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      4.83G          0      147.5          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.5it/s 1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.2it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      4.83G          0        147          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.3it/s 1.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.2it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      4.83G          0      147.8          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 2.8it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.2it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      4.83G          0      147.2          0          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5/5 3.5it/s 1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 3.5it/s 0.9s\n",
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 0.025 hours.\n",
            "Optimizer stripped from /content/yolo_datasets/runs/detect/train_result2/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/yolo_datasets/runs/detect/train_result2/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/yolo_datasets/runs/detect/train_result2/weights/best.pt...\n",
            "Ultralytics 8.3.249 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 2.8it/s 1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:654: RuntimeWarning: Mean of empty slice.\n",
            "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n",
            "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolo_datasets/runs/detect/train_result2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/yolo_datasets/runs/detect/train_result2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vAM7Llh1E2n",
        "outputId": "0fbb7149-fd72-4801-f986-a97831742688"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "args.yaml\t\t\t results.png\t\tval_batch0_pred.jpg\n",
            "BoxF1_curve.png\t\t\t train_batch0.jpg\tval_batch1_labels.jpg\n",
            "BoxP_curve.png\t\t\t train_batch1.jpg\tval_batch1_pred.jpg\n",
            "BoxPR_curve.png\t\t\t train_batch2.jpg\tval_batch2_labels.jpg\n",
            "BoxR_curve.png\t\t\t train_batch50.jpg\tval_batch2_pred.jpg\n",
            "confusion_matrix_normalized.png  train_batch51.jpg\tweights\n",
            "confusion_matrix.png\t\t train_batch52.jpg\n",
            "results.csv\t\t\t val_batch0_labels.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌïôÏäµÎêú Î™®Îç∏Î°ú Í≤ÄÏ¶ùÏùÑ Ìï¥Î≥¥Ïûê\n",
        "\n",
        "model = YOLO('/content/yolo_datasets/runs/detect/train_result/weights/best.pt')\n",
        "\n",
        "results = model.val(\n",
        "    source='/content/yolo_datasets/data.yaml',\n",
        "    imgsz=640,\n",
        "    iou=0.5,\n",
        "    device=0,\n",
        "    workers=2,               # Îç∞Ïù¥ÌÑ∞ Î°úÎìú Ïãú Î≥ëÎ†¨ Ï≤òÎ¶¨Ìï† ÏõåÏª§ Ïàò\n",
        "    half=True,               # FP16 Ïó∞ÏÇ∞ ÌôúÏÑ±Ìôî (ÏÜçÎèÑ Ìñ•ÏÉÅ)\n",
        "    split=\"val\"\n",
        ")\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tk3BUFDmgz0m",
        "outputId": "ca67f2d2-58c4-4cf5-c9ee-bdb400d56826"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.249 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 2344.5¬±1424.3 MB/s, size: 182.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_datasets/labels/val.cache... 36 images, 140 backgrounds, 36 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 176/176 354.6Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road11.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road110.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road138.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road200.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road212.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road238.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road248.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road250.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road276.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road312.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road335.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road354.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road373.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road386.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road388.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road391.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road397.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road419.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road43.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road436.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road437.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road512.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road551.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road562.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road569.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road575.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road584.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road597.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road599.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road610.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road66.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road69.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road797.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road809.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road864.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "\u001b[34m\u001b[1mval: \u001b[0m/content/yolo_datasets/images/val/road9.png: ignoring corrupt image/label: 'utf-8' codec can't decode byte 0x89 in position 0: invalid start byte\n",
            "WARNING ‚ö†Ô∏è Labels are missing or empty in /content/yolo_datasets/labels/val.cache, training may not work correctly. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 2.6it/s 3.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:654: RuntimeWarning: Mean of empty slice.\n",
            "  ax.plot(px, py.mean(1), linewidth=3, color=\"blue\", label=f\"all classes {ap[:, 0].mean():.3f} mAP@0.5\")\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:700: RuntimeWarning: Mean of empty slice.\n",
            "  y = smooth(py.mean(0), 0.1)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:130: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.12/dist-packages/ultralytics/utils/metrics.py:836: RuntimeWarning: Mean of empty slice.\n",
            "  i = smooth(f1_curve.mean(0), 0.1).argmax()  # max F1 index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        140          0          0          0          0          0\n",
            "WARNING ‚ö†Ô∏è no labels found in detect set, cannot compute metrics without labels\n",
            "Speed: 2.3ms preprocess, 14.3ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolo_datasets/runs/detect/val\u001b[0m\n",
            "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
            "\n",
            "ap_class_index: array([], dtype=int64)\n",
            "box: ultralytics.utils.metrics.Metric object\n",
            "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7afc8b4e1970>\n",
            "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
            "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0,\n",
            "                  0,           0,           0,           0,           0,           0,           0,           0,           0,           0,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([], shape=(0, 1000), dtype=float64), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([], shape=(0, 1000), dtype=float64), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
            "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
            "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
            "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
            "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
            "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
            "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
            "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
            "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
            "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
            "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
            "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
            "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
            "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
            "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
            "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
            "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
            "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
            "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
            "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
            "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
            "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
            "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
            "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
            "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
            "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
            "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
            "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
            "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
            "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
            "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
            "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
            "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
            "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
            "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
            "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
            "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
            "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
            "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
            "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
            "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
            "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([], shape=(0, 1000), dtype=float64), 'Confidence', 'Recall']]\n",
            "fitness: np.float64(0.0)\n",
            "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
            "maps: array([          0,           0,           0,           0])\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "nt_per_class: array([0, 0, 0, 0])\n",
            "nt_per_image: array([0, 0, 0, 0])\n",
            "results_dict: {'metrics/precision(B)': 0.0, 'metrics/recall(B)': 0.0, 'metrics/mAP50(B)': 0.0, 'metrics/mAP50-95(B)': 0.0, 'fitness': 0.0}\n",
            "save_dir: PosixPath('/content/yolo_datasets/runs/detect/val')\n",
            "speed: {'preprocess': 2.3496709928541093, 'inference': 14.280955392856802, 'loss': 0.0350541428555776, 'postprocess': 2.9731303571436127}\n",
            "stats: {'tp': [], 'conf': [], 'pred_cls': [], 'target_cls': [], 'target_img': []}\n",
            "task: 'detect'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('/content/yolo_datasets/runs/detect/train_result/weights/best.pt')\n",
        "\n",
        "results = model.predict(\n",
        "    source='/content/yolo_datasets/images/val',\n",
        "    imgsz=640,\n",
        "    conf=0.05,\n",
        "    device=0,\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    save_conf=True\n",
        ")\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-3yf8lWMq7ce",
        "outputId": "81186759-ad8c-4016-e46b-fe7647a7cc94"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mÏä§Ìä∏Î¶¨Î∞ç Ï∂úÎ†• ÎÇ¥Ïö©Ïù¥ Í∏∏Ïñ¥ÏÑú ÎßàÏßÄÎßâ 5000Ï§ÑÏù¥ ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.\u001b[0m\n",
            "       [[124, 130, 116],\n",
            "        [127, 131, 119],\n",
            "        [128, 132, 120],\n",
            "        ...,\n",
            "        [157, 165, 154],\n",
            "        [160, 168, 155],\n",
            "        [162, 171, 158]],\n",
            "\n",
            "       [[125, 131, 117],\n",
            "        [126, 132, 118],\n",
            "        [125, 131, 117],\n",
            "        ...,\n",
            "        [152, 163, 148],\n",
            "        [137, 148, 132],\n",
            "        [135, 146, 130]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road467.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.4052320000009786, 'inference': 7.4639669999214675, 'postprocess': 0.6951649997972709}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[237, 202, 126],\n",
            "        [239, 201, 128],\n",
            "        [238, 200, 127],\n",
            "        ...,\n",
            "        [243, 205, 131],\n",
            "        [242, 205, 129],\n",
            "        [243, 204, 130]],\n",
            "\n",
            "       [[238, 202, 127],\n",
            "        [238, 200, 127],\n",
            "        [238, 200, 127],\n",
            "        ...,\n",
            "        [243, 204, 131],\n",
            "        [242, 205, 130],\n",
            "        [244, 205, 132]],\n",
            "\n",
            "       [[237, 201, 126],\n",
            "        [237, 199, 127],\n",
            "        [238, 200, 127],\n",
            "        ...,\n",
            "        [243, 205, 131],\n",
            "        [243, 206, 130],\n",
            "        [244, 205, 131]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[124,  99,  62],\n",
            "        [125,  99,  62],\n",
            "        [125,  99,  62],\n",
            "        ...,\n",
            "        [ 66,  49,  20],\n",
            "        [ 58,  44,  14],\n",
            "        [ 62,  49,  23]],\n",
            "\n",
            "       [[125,  98,  59],\n",
            "        [125,  98,  59],\n",
            "        [124,  98,  59],\n",
            "        ...,\n",
            "        [ 66,  49,  19],\n",
            "        [ 59,  45,  15],\n",
            "        [ 61,  49,  23]],\n",
            "\n",
            "       [[127, 102,  60],\n",
            "        [129, 104,  62],\n",
            "        [127, 103,  62],\n",
            "        ...,\n",
            "        [ 65,  50,  19],\n",
            "        [ 57,  44,  12],\n",
            "        [ 58,  47,  18]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road475.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.408206999916729, 'inference': 9.361418000025878, 'postprocess': 0.6791020000491699}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[239, 191, 108],\n",
            "        [241, 190, 109],\n",
            "        [241, 190, 109],\n",
            "        ...,\n",
            "        [ 73,  41,   9],\n",
            "        [ 73,  41,   9],\n",
            "        [ 73,  41,   9]],\n",
            "\n",
            "       [[239, 191, 108],\n",
            "        [242, 190, 109],\n",
            "        [242, 191, 110],\n",
            "        ...,\n",
            "        [ 72,  40,   9],\n",
            "        [ 72,  40,   9],\n",
            "        [ 72,  40,   9]],\n",
            "\n",
            "       [[241, 191, 109],\n",
            "        [241, 190, 109],\n",
            "        [241, 190, 109],\n",
            "        ...,\n",
            "        [ 72,  40,   9],\n",
            "        [ 72,  40,   9],\n",
            "        [ 72,  40,   9]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 51,  33,   7],\n",
            "        [ 67,  50,  16],\n",
            "        [ 78,  59,  26],\n",
            "        ...,\n",
            "        [ 69,  48,  29],\n",
            "        [ 50,  28,  10],\n",
            "        [ 38,  15,   2]],\n",
            "\n",
            "       [[ 52,  34,   6],\n",
            "        [ 72,  52,  22],\n",
            "        [ 64,  45,  13],\n",
            "        ...,\n",
            "        [ 60,  39,  22],\n",
            "        [ 39,  18,   2],\n",
            "        [ 46,  23,   7]],\n",
            "\n",
            "       [[ 53,  34,   7],\n",
            "        [ 71,  52,  21],\n",
            "        [ 61,  43,  14],\n",
            "        ...,\n",
            "        [ 39,  22,   4],\n",
            "        [ 50,  32,   8],\n",
            "        [ 62,  43,  18]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road479.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 3.8836470000660483, 'inference': 12.492513999859511, 'postprocess': 0.6710390000534971}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[225, 175,  96],\n",
            "        [227, 174,  98],\n",
            "        [227, 174,  98],\n",
            "        ...,\n",
            "        [227, 174,  98],\n",
            "        [226, 173,  97],\n",
            "        [226, 173,  97]],\n",
            "\n",
            "       [[226, 175,  97],\n",
            "        [227, 174,  98],\n",
            "        [227, 174,  98],\n",
            "        ...,\n",
            "        [227, 174,  98],\n",
            "        [226, 173,  97],\n",
            "        [226, 173,  97]],\n",
            "\n",
            "       [[226, 175,  97],\n",
            "        [227, 174,  98],\n",
            "        [227, 174,  98],\n",
            "        ...,\n",
            "        [226, 173,  97],\n",
            "        [226, 173,  97],\n",
            "        [226, 173,  97]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[218, 240, 231],\n",
            "        [220, 240, 233],\n",
            "        [217, 240, 232],\n",
            "        ...,\n",
            "        [ 65,  70,  66],\n",
            "        [129, 136, 128],\n",
            "        [ 66,  73,  60]],\n",
            "\n",
            "       [[213, 234, 226],\n",
            "        [215, 235, 228],\n",
            "        [214, 236, 229],\n",
            "        ...,\n",
            "        [ 95, 100,  96],\n",
            "        [221, 228, 220],\n",
            "        [113, 120, 108]],\n",
            "\n",
            "       [[213, 236, 227],\n",
            "        [215, 236, 228],\n",
            "        [214, 238, 229],\n",
            "        ...,\n",
            "        [ 90,  98,  91],\n",
            "        [218, 226, 217],\n",
            "        [110, 118, 104]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road481.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.4432180000530934, 'inference': 12.954675000173665, 'postprocess': 0.7714809999015415}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[120, 108,  74],\n",
            "        [133, 117,  87],\n",
            "        [104,  86,  55],\n",
            "        ...,\n",
            "        [138, 117,  78],\n",
            "        [149, 128,  90],\n",
            "        [156, 134,  97]],\n",
            "\n",
            "       [[127, 115,  81],\n",
            "        [134, 118,  87],\n",
            "        [ 97,  80,  49],\n",
            "        ...,\n",
            "        [128, 106,  71],\n",
            "        [122, 101,  65],\n",
            "        [111,  89,  53]],\n",
            "\n",
            "       [[116, 101,  67],\n",
            "        [126, 109,  77],\n",
            "        [ 81,  64,  32],\n",
            "        ...,\n",
            "        [ 79,  57,  23],\n",
            "        [ 76,  54,  19],\n",
            "        [103,  81,  47]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[131, 139, 129],\n",
            "        [136, 143, 134],\n",
            "        [136, 143, 134],\n",
            "        ...,\n",
            "        [107,  92,  67],\n",
            "        [102,  85,  60],\n",
            "        [ 98,  80,  54]],\n",
            "\n",
            "       [[130, 138, 128],\n",
            "        [133, 140, 131],\n",
            "        [134, 141, 132],\n",
            "        ...,\n",
            "        [106,  90,  66],\n",
            "        [109,  94,  67],\n",
            "        [102,  86,  59]],\n",
            "\n",
            "       [[123, 132, 121],\n",
            "        [126, 134, 124],\n",
            "        [132, 140, 130],\n",
            "        ...,\n",
            "        [ 98,  86,  59],\n",
            "        [108,  96,  67],\n",
            "        [103,  92,  61]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road486.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.4660359999870707, 'inference': 10.109753000051569, 'postprocess': 0.6156709998776932}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[217, 176, 102],\n",
            "        [218, 174, 103],\n",
            "        [218, 174, 103],\n",
            "        ...,\n",
            "        [227, 183, 111],\n",
            "        [226, 182, 110],\n",
            "        [226, 182, 110]],\n",
            "\n",
            "       [[217, 176, 102],\n",
            "        [219, 175, 104],\n",
            "        [220, 176, 105],\n",
            "        ...,\n",
            "        [226, 182, 110],\n",
            "        [227, 183, 111],\n",
            "        [226, 182, 110]],\n",
            "\n",
            "       [[217, 176, 102],\n",
            "        [219, 174, 104],\n",
            "        [220, 176, 105],\n",
            "        ...,\n",
            "        [227, 183, 111],\n",
            "        [227, 183, 111],\n",
            "        [227, 183, 111]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 78,  92,  92],\n",
            "        [130, 146, 146],\n",
            "        [212, 235, 230],\n",
            "        ...,\n",
            "        [139, 134, 115],\n",
            "        [137, 131, 112],\n",
            "        [136, 130, 111]],\n",
            "\n",
            "       [[ 87, 100,  98],\n",
            "        [109, 121, 120],\n",
            "        [157, 175, 171],\n",
            "        ...,\n",
            "        [140, 134, 115],\n",
            "        [135, 129, 110],\n",
            "        [134, 126, 107]],\n",
            "\n",
            "       [[ 90, 104, 100],\n",
            "        [111, 125, 121],\n",
            "        [162, 179, 174],\n",
            "        ...,\n",
            "        [138, 134, 112],\n",
            "        [134, 130, 108],\n",
            "        [131, 124, 104]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road495.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.456563000123424, 'inference': 10.813490000145976, 'postprocess': 0.46806199998172815}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[216, 175, 100],\n",
            "        [217, 173, 101],\n",
            "        [216, 172, 100],\n",
            "        ...,\n",
            "        [222, 178, 106],\n",
            "        [226, 182, 110],\n",
            "        [226, 182, 110]],\n",
            "\n",
            "       [[217, 176, 101],\n",
            "        [218, 174, 102],\n",
            "        [218, 174, 102],\n",
            "        ...,\n",
            "        [227, 183, 112],\n",
            "        [227, 183, 113],\n",
            "        [225, 181, 110]],\n",
            "\n",
            "       [[219, 176, 103],\n",
            "        [218, 174, 102],\n",
            "        [218, 174, 102],\n",
            "        ...,\n",
            "        [234, 189, 121],\n",
            "        [232, 187, 119],\n",
            "        [224, 179, 111]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[108, 104,  76],\n",
            "        [ 94,  89,  60],\n",
            "        [135, 139, 107],\n",
            "        ...,\n",
            "        [107,  98,  67],\n",
            "        [107,  97,  65],\n",
            "        [113, 104,  69]],\n",
            "\n",
            "       [[110, 106,  77],\n",
            "        [ 92,  88,  59],\n",
            "        [138, 142, 110],\n",
            "        ...,\n",
            "        [110, 101,  70],\n",
            "        [106,  96,  64],\n",
            "        [111, 100,  66]],\n",
            "\n",
            "       [[ 99,  96,  66],\n",
            "        [ 95,  92,  62],\n",
            "        [139, 144, 112],\n",
            "        ...,\n",
            "        [109, 104,  70],\n",
            "        [106,  99,  64],\n",
            "        [102,  93,  55]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road497.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.5818650001383503, 'inference': 6.566865999957372, 'postprocess': 0.5576389999077946}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[199, 198, 222],\n",
            "        [200, 200, 219],\n",
            "        [181, 181, 188],\n",
            "        ...,\n",
            "        [201, 190, 180],\n",
            "        [201, 190, 180],\n",
            "        [201, 190, 180]],\n",
            "\n",
            "       [[202, 201, 224],\n",
            "        [201, 200, 219],\n",
            "        [185, 185, 193],\n",
            "        ...,\n",
            "        [202, 191, 181],\n",
            "        [202, 191, 181],\n",
            "        [202, 191, 181]],\n",
            "\n",
            "       [[203, 202, 224],\n",
            "        [202, 202, 222],\n",
            "        [190, 189, 200],\n",
            "        ...,\n",
            "        [202, 191, 181],\n",
            "        [202, 191, 181],\n",
            "        [202, 191, 181]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 25,  21,  18],\n",
            "        [ 25,  21,  18],\n",
            "        [ 25,  21,  18],\n",
            "        ...,\n",
            "        [ 37,  38,  41],\n",
            "        [ 37,  38,  41],\n",
            "        [ 37,  37,  41]],\n",
            "\n",
            "       [[ 25,  21,  18],\n",
            "        [ 25,  21,  18],\n",
            "        [ 25,  21,  18],\n",
            "        ...,\n",
            "        [ 39,  38,  41],\n",
            "        [ 39,  38,  41],\n",
            "        [ 39,  38,  41]],\n",
            "\n",
            "       [[ 28,  24,  21],\n",
            "        [ 28,  24,  21],\n",
            "        [ 29,  24,  22],\n",
            "        ...,\n",
            "        [ 37,  36,  39],\n",
            "        [ 37,  36,  39],\n",
            "        [ 37,  36,  39]]], dtype=uint8)\n",
            "orig_shape: (400, 267)\n",
            "path: '/content/yolo_datasets/images/val/road50.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.382635999992999, 'inference': 10.67135500011318, 'postprocess': 0.703863999888199}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[224, 181, 106],\n",
            "        [226, 180, 108],\n",
            "        [226, 180, 108],\n",
            "        ...,\n",
            "        [224, 179, 103],\n",
            "        [224, 179, 103],\n",
            "        [222, 177, 101]],\n",
            "\n",
            "       [[225, 181, 106],\n",
            "        [226, 180, 108],\n",
            "        [226, 180, 108],\n",
            "        ...,\n",
            "        [226, 181, 105],\n",
            "        [224, 179, 103],\n",
            "        [223, 178, 102]],\n",
            "\n",
            "       [[226, 182, 108],\n",
            "        [227, 181, 109],\n",
            "        [226, 180, 108],\n",
            "        ...,\n",
            "        [225, 180, 104],\n",
            "        [224, 179, 103],\n",
            "        [225, 180, 104]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[116, 124, 118],\n",
            "        [ 72,  79,  73],\n",
            "        [ 70,  74,  69],\n",
            "        ...,\n",
            "        [224, 225, 199],\n",
            "        [228, 223, 181],\n",
            "        [202, 196, 151]],\n",
            "\n",
            "       [[100, 107,  99],\n",
            "        [ 90,  96,  90],\n",
            "        [ 84,  90,  85],\n",
            "        ...,\n",
            "        [233, 231, 204],\n",
            "        [240, 234, 192],\n",
            "        [236, 230, 184]],\n",
            "\n",
            "       [[104, 112, 103],\n",
            "        [102, 109, 101],\n",
            "        [105, 111, 105],\n",
            "        ...,\n",
            "        [228, 229, 199],\n",
            "        [237, 234, 189],\n",
            "        [229, 226, 177]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road505.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.4835419999362784, 'inference': 10.352538999995886, 'postprocess': 0.7299129999864817}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[218, 180, 105],\n",
            "        [220, 178, 107],\n",
            "        [219, 177, 106],\n",
            "        ...,\n",
            "        [219, 177, 106],\n",
            "        [219, 177, 106],\n",
            "        [220, 178, 107]],\n",
            "\n",
            "       [[220, 179, 106],\n",
            "        [220, 178, 107],\n",
            "        [220, 178, 107],\n",
            "        ...,\n",
            "        [219, 177, 106],\n",
            "        [219, 177, 106],\n",
            "        [219, 177, 106]],\n",
            "\n",
            "       [[220, 179, 106],\n",
            "        [220, 178, 107],\n",
            "        [220, 178, 107],\n",
            "        ...,\n",
            "        [219, 177, 106],\n",
            "        [219, 177, 106],\n",
            "        [219, 177, 106]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 73,  83,  81],\n",
            "        [ 72,  80,  80],\n",
            "        [ 57,  65,  64],\n",
            "        ...,\n",
            "        [133, 166, 171],\n",
            "        [127, 159, 165],\n",
            "        [110, 142, 147]],\n",
            "\n",
            "       [[ 86,  98,  95],\n",
            "        [ 83,  94,  93],\n",
            "        [ 62,  70,  70],\n",
            "        ...,\n",
            "        [134, 167, 173],\n",
            "        [135, 166, 172],\n",
            "        [131, 163, 169]],\n",
            "\n",
            "       [[ 79,  91,  88],\n",
            "        [ 79,  91,  88],\n",
            "        [ 62,  71,  69],\n",
            "        ...,\n",
            "        [137, 174, 177],\n",
            "        [132, 169, 171],\n",
            "        [126, 160, 163]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road510.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.4660620001668576, 'inference': 9.424723999927664, 'postprocess': 0.7083759999204631}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[217, 183, 128],\n",
            "        [215, 176, 124],\n",
            "        [216, 177, 125],\n",
            "        ...,\n",
            "        [208, 149,  78],\n",
            "        [208, 149,  78],\n",
            "        [208, 149,  78]],\n",
            "\n",
            "       [[217, 186, 130],\n",
            "        [217, 182, 130],\n",
            "        [215, 181, 128],\n",
            "        ...,\n",
            "        [209, 150,  79],\n",
            "        [209, 150,  79],\n",
            "        [209, 150,  79]],\n",
            "\n",
            "       [[216, 185, 132],\n",
            "        [216, 185, 133],\n",
            "        [215, 184, 131],\n",
            "        ...,\n",
            "        [209, 150,  79],\n",
            "        [209, 150,  79],\n",
            "        [209, 150,  79]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[107, 121, 122],\n",
            "        [109, 122, 124],\n",
            "        [112, 125, 127],\n",
            "        ...,\n",
            "        [ 71,  81,  79],\n",
            "        [ 77,  89,  87],\n",
            "        [ 75,  89,  87]],\n",
            "\n",
            "       [[106, 120, 121],\n",
            "        [108, 121, 123],\n",
            "        [109, 122, 124],\n",
            "        ...,\n",
            "        [ 73,  85,  83],\n",
            "        [ 74,  85,  84],\n",
            "        [ 81,  93,  92]],\n",
            "\n",
            "       [[106, 121, 121],\n",
            "        [109, 123, 124],\n",
            "        [108, 122, 123],\n",
            "        ...,\n",
            "        [ 78,  95,  90],\n",
            "        [ 75,  91,  86],\n",
            "        [ 75,  92,  88]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road512.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.4419389999366103, 'inference': 9.540711999989071, 'postprocess': 0.741952999987916}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[253, 240, 230],\n",
            "        [253, 240, 230],\n",
            "        [252, 239, 229],\n",
            "        ...,\n",
            "        [255, 249, 239],\n",
            "        [255, 249, 239],\n",
            "        [255, 249, 239]],\n",
            "\n",
            "       [[253, 241, 231],\n",
            "        [253, 241, 231],\n",
            "        [253, 240, 230],\n",
            "        ...,\n",
            "        [255, 249, 239],\n",
            "        [255, 249, 239],\n",
            "        [255, 249, 239]],\n",
            "\n",
            "       [[254, 243, 233],\n",
            "        [254, 243, 233],\n",
            "        [254, 242, 232],\n",
            "        ...,\n",
            "        [255, 249, 239],\n",
            "        [255, 249, 239],\n",
            "        [255, 249, 239]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[248, 238, 232],\n",
            "        [248, 238, 232],\n",
            "        [248, 238, 232],\n",
            "        ...,\n",
            "        [255, 250, 248],\n",
            "        [255, 250, 248],\n",
            "        [255, 250, 248]],\n",
            "\n",
            "       [[248, 238, 232],\n",
            "        [248, 238, 232],\n",
            "        [248, 238, 232],\n",
            "        ...,\n",
            "        [255, 250, 248],\n",
            "        [255, 250, 248],\n",
            "        [255, 250, 248]],\n",
            "\n",
            "       [[248, 238, 232],\n",
            "        [248, 238, 232],\n",
            "        [248, 238, 232],\n",
            "        ...,\n",
            "        [255, 250, 248],\n",
            "        [255, 250, 248],\n",
            "        [255, 250, 248]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road52.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.419303999886324, 'inference': 9.722951999947327, 'postprocess': 0.6603699998777302}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[205, 140,  55],\n",
            "        [210, 141,  59],\n",
            "        [209, 141,  59],\n",
            "        ...,\n",
            "        [198, 132,  48],\n",
            "        [197, 132,  48],\n",
            "        [196, 131,  48]],\n",
            "\n",
            "       [[209, 142,  59],\n",
            "        [210, 141,  60],\n",
            "        [211, 142,  60],\n",
            "        ...,\n",
            "        [198, 131,  48],\n",
            "        [197, 131,  48],\n",
            "        [197, 132,  48]],\n",
            "\n",
            "       [[207, 142,  57],\n",
            "        [211, 142,  61],\n",
            "        [210, 141,  60],\n",
            "        ...,\n",
            "        [199, 132,  48],\n",
            "        [196, 131,  48],\n",
            "        [197, 132,  48]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[103, 125, 121],\n",
            "        [142, 169, 166],\n",
            "        [167, 195, 191],\n",
            "        ...,\n",
            "        [ 92, 118, 132],\n",
            "        [117, 149, 162],\n",
            "        [170, 210, 217]],\n",
            "\n",
            "       [[119, 134, 126],\n",
            "        [158, 179, 172],\n",
            "        [170, 191, 183],\n",
            "        ...,\n",
            "        [107, 133, 143],\n",
            "        [141, 172, 180],\n",
            "        [137, 163, 171]],\n",
            "\n",
            "       [[153, 159, 140],\n",
            "        [156, 164, 146],\n",
            "        [164, 170, 151],\n",
            "        ...,\n",
            "        [ 23,  44,  49],\n",
            "        [ 53,  69,  74],\n",
            "        [ 18,  33,  37]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road520.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.3327290000452194, 'inference': 10.872445999893898, 'postprocess': 0.7436590001361765}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[188, 125,  48],\n",
            "        [191, 124,  51],\n",
            "        [192, 125,  50],\n",
            "        ...,\n",
            "        [205, 134,  59],\n",
            "        [206, 134,  60],\n",
            "        [205, 134,  59]],\n",
            "\n",
            "       [[188, 125,  48],\n",
            "        [190, 123,  49],\n",
            "        [191, 124,  49],\n",
            "        ...,\n",
            "        [205, 134,  59],\n",
            "        [205, 134,  59],\n",
            "        [205, 134,  59]],\n",
            "\n",
            "       [[191, 124,  49],\n",
            "        [191, 124,  49],\n",
            "        [191, 124,  49],\n",
            "        ...,\n",
            "        [204, 134,  59],\n",
            "        [205, 134,  59],\n",
            "        [205, 134,  59]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[174, 189, 184],\n",
            "        [ 95, 104, 103],\n",
            "        [165, 177, 174],\n",
            "        ...,\n",
            "        [ 11,   8,   4],\n",
            "        [  9,   6,   4],\n",
            "        [  6,   3,   4]],\n",
            "\n",
            "       [[ 69,  72,  67],\n",
            "        [ 55,  56,  52],\n",
            "        [ 52,  49,  47],\n",
            "        ...,\n",
            "        [ 10,   8,   4],\n",
            "        [  9,   6,   4],\n",
            "        [  8,   6,   6]],\n",
            "\n",
            "       [[ 65,  68,  62],\n",
            "        [ 50,  52,  46],\n",
            "        [ 25,  24,  18],\n",
            "        ...,\n",
            "        [  6,   6,   1],\n",
            "        [  5,   5,   1],\n",
            "        [  8,   9,   6]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road524.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.447132000042984, 'inference': 9.9034740001116, 'postprocess': 0.7315000000289729}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[205, 138,  60],\n",
            "        [207, 135,  61],\n",
            "        [206, 135,  60],\n",
            "        ...,\n",
            "        [219, 145,  66],\n",
            "        [219, 145,  66],\n",
            "        [220, 146,  67]],\n",
            "\n",
            "       [[204, 137,  59],\n",
            "        [207, 135,  61],\n",
            "        [206, 135,  60],\n",
            "        ...,\n",
            "        [219, 145,  65],\n",
            "        [218, 144,  65],\n",
            "        [219, 145,  65]],\n",
            "\n",
            "       [[206, 137,  60],\n",
            "        [208, 136,  62],\n",
            "        [206, 135,  61],\n",
            "        ...,\n",
            "        [219, 145,  65],\n",
            "        [219, 145,  65],\n",
            "        [219, 145,  66]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[145, 207, 215],\n",
            "        [149, 211, 217],\n",
            "        [150, 213, 218],\n",
            "        ...,\n",
            "        [ 12,  38,  55],\n",
            "        [  3,  13,  27],\n",
            "        [ 21,  36,  46]],\n",
            "\n",
            "       [[157, 217, 222],\n",
            "        [162, 220, 226],\n",
            "        [165, 223, 229],\n",
            "        ...,\n",
            "        [ 11,  40,  55],\n",
            "        [  4,  14,  25],\n",
            "        [ 13,  28,  37]],\n",
            "\n",
            "       [[185, 233, 239],\n",
            "        [186, 232, 239],\n",
            "        [181, 226, 234],\n",
            "        ...,\n",
            "        [ 10,  43,  55],\n",
            "        [  3,  14,  21],\n",
            "        [ 10,  24,  29]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road525.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 3.171919999886086, 'inference': 9.294222000107766, 'postprocess': 0.7369479999397299}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[193, 195, 190],\n",
            "        [193, 195, 190],\n",
            "        [193, 195, 190],\n",
            "        ...,\n",
            "        [197, 196, 195],\n",
            "        [200, 198, 197],\n",
            "        [232, 230, 229]],\n",
            "\n",
            "       [[193, 194, 190],\n",
            "        [193, 194, 190],\n",
            "        [193, 194, 190],\n",
            "        ...,\n",
            "        [197, 195, 195],\n",
            "        [200, 198, 197],\n",
            "        [232, 230, 229]],\n",
            "\n",
            "       [[192, 194, 189],\n",
            "        [192, 194, 189],\n",
            "        [192, 194, 189],\n",
            "        ...,\n",
            "        [197, 195, 195],\n",
            "        [200, 198, 197],\n",
            "        [232, 230, 230]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[149, 159, 157],\n",
            "        [149, 159, 157],\n",
            "        [149, 159, 157],\n",
            "        ...,\n",
            "        [154, 158, 159],\n",
            "        [155, 159, 160],\n",
            "        [155, 159, 160]],\n",
            "\n",
            "       [[149, 159, 157],\n",
            "        [149, 159, 157],\n",
            "        [149, 159, 157],\n",
            "        ...,\n",
            "        [154, 157, 158],\n",
            "        [156, 159, 160],\n",
            "        [156, 159, 160]],\n",
            "\n",
            "       [[146, 159, 156],\n",
            "        [146, 159, 156],\n",
            "        [146, 159, 156],\n",
            "        ...,\n",
            "        [155, 157, 157],\n",
            "        [156, 158, 158],\n",
            "        [156, 158, 158]]], dtype=uint8)\n",
            "orig_shape: (290, 400)\n",
            "path: '/content/yolo_datasets/images/val/road53.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 3.460296999946877, 'inference': 10.099520000039774, 'postprocess': 0.7209369998690818}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[220, 185, 117],\n",
            "        [222, 184, 118],\n",
            "        [222, 184, 118],\n",
            "        ...,\n",
            "        [219, 179, 112],\n",
            "        [219, 179, 112],\n",
            "        [218, 178, 111]],\n",
            "\n",
            "       [[221, 185, 117],\n",
            "        [222, 184, 118],\n",
            "        [222, 184, 118],\n",
            "        ...,\n",
            "        [219, 179, 112],\n",
            "        [219, 179, 112],\n",
            "        [220, 180, 113]],\n",
            "\n",
            "       [[221, 184, 118],\n",
            "        [222, 184, 118],\n",
            "        [222, 184, 118],\n",
            "        ...,\n",
            "        [219, 179, 112],\n",
            "        [218, 178, 111],\n",
            "        [220, 180, 113]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 64,  59,  42],\n",
            "        [ 63,  56,  41],\n",
            "        [ 62,  55,  40],\n",
            "        ...,\n",
            "        [ 59,  44,  17],\n",
            "        [ 58,  44,  15],\n",
            "        [ 60,  44,  15]],\n",
            "\n",
            "       [[ 61,  55,  38],\n",
            "        [ 63,  56,  40],\n",
            "        [ 61,  54,  39],\n",
            "        ...,\n",
            "        [ 61,  46,  18],\n",
            "        [ 61,  47,  17],\n",
            "        [ 61,  47,  17]],\n",
            "\n",
            "       [[ 61,  57,  38],\n",
            "        [ 62,  56,  39],\n",
            "        [ 61,  55,  39],\n",
            "        ...,\n",
            "        [ 59,  47,  17],\n",
            "        [ 56,  45,  13],\n",
            "        [ 57,  46,  13]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road535.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.9173610000725603, 'inference': 11.394053000003623, 'postprocess': 0.8165889998963394}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[224, 191, 122],\n",
            "        [226, 190, 124],\n",
            "        [225, 189, 123],\n",
            "        ...,\n",
            "        [223, 185, 119],\n",
            "        [223, 185, 119],\n",
            "        [223, 185, 119]],\n",
            "\n",
            "       [[224, 190, 122],\n",
            "        [225, 189, 123],\n",
            "        [225, 189, 123],\n",
            "        ...,\n",
            "        [223, 185, 119],\n",
            "        [223, 185, 119],\n",
            "        [223, 185, 119]],\n",
            "\n",
            "       [[224, 190, 124],\n",
            "        [225, 189, 123],\n",
            "        [225, 189, 123],\n",
            "        ...,\n",
            "        [223, 185, 119],\n",
            "        [223, 185, 119],\n",
            "        [223, 185, 119]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 85,  78,  55],\n",
            "        [ 86,  78,  56],\n",
            "        [ 88,  80,  58],\n",
            "        ...,\n",
            "        [ 58,  45,  23],\n",
            "        [ 58,  46,  22],\n",
            "        [ 59,  46,  23]],\n",
            "\n",
            "       [[ 77,  69,  45],\n",
            "        [ 74,  66,  42],\n",
            "        [ 82,  75,  51],\n",
            "        ...,\n",
            "        [ 59,  46,  23],\n",
            "        [ 59,  47,  23],\n",
            "        [ 59,  46,  23]],\n",
            "\n",
            "       [[ 63,  56,  31],\n",
            "        [ 68,  60,  36],\n",
            "        [ 73,  66,  42],\n",
            "        ...,\n",
            "        [ 55,  45,  21],\n",
            "        [ 55,  45,  20],\n",
            "        [ 57,  47,  23]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road536.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.3191029999907187, 'inference': 8.702911000000313, 'postprocess': 0.6622910000260163}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[222, 236, 216],\n",
            "        [231, 241, 225],\n",
            "        [226, 237, 221],\n",
            "        ...,\n",
            "        [113, 102,  74],\n",
            "        [116, 104,  79],\n",
            "        [ 99,  87,  62]],\n",
            "\n",
            "       [[224, 238, 219],\n",
            "        [224, 235, 219],\n",
            "        [225, 236, 220],\n",
            "        ...,\n",
            "        [115, 104,  76],\n",
            "        [104,  92,  67],\n",
            "        [ 91,  80,  54]],\n",
            "\n",
            "       [[220, 232, 213],\n",
            "        [222, 231, 214],\n",
            "        [221, 232, 215],\n",
            "        ...,\n",
            "        [106,  94,  66],\n",
            "        [ 90,  79,  53],\n",
            "        [103,  91,  66]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[118, 117,  91],\n",
            "        [117, 115,  90],\n",
            "        [118, 117,  91],\n",
            "        ...,\n",
            "        [122, 121, 101],\n",
            "        [115, 113,  93],\n",
            "        [115, 114,  94]],\n",
            "\n",
            "       [[116, 113,  86],\n",
            "        [117, 113,  87],\n",
            "        [114, 113,  86],\n",
            "        ...,\n",
            "        [105, 100,  81],\n",
            "        [ 98,  94,  75],\n",
            "        [ 97,  93,  74]],\n",
            "\n",
            "       [[112, 110,  82],\n",
            "        [115, 113,  86],\n",
            "        [114, 113,  85],\n",
            "        ...,\n",
            "        [109, 107,  84],\n",
            "        [103, 103,  80],\n",
            "        [ 95,  95,  72]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road538.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.6713130000644014, 'inference': 7.725037000000157, 'postprocess': 0.6896610000239889}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[109,  97,  84],\n",
            "        [109,  97,  84],\n",
            "        [109,  97,  84],\n",
            "        ...,\n",
            "        [ 86,  71,  57],\n",
            "        [ 86,  71,  57],\n",
            "        [ 86,  71,  57]],\n",
            "\n",
            "       [[109,  97,  84],\n",
            "        [109,  97,  84],\n",
            "        [109,  97,  84],\n",
            "        ...,\n",
            "        [ 87,  71,  57],\n",
            "        [ 86,  71,  57],\n",
            "        [ 86,  71,  57]],\n",
            "\n",
            "       [[109,  97,  84],\n",
            "        [109,  97,  84],\n",
            "        [109,  97,  84],\n",
            "        ...,\n",
            "        [ 88,  72,  58],\n",
            "        [ 87,  71,  57],\n",
            "        [ 87,  71,  57]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[  8,   4,   9],\n",
            "        [  9,   5,  10],\n",
            "        [ 11,   6,  11],\n",
            "        ...,\n",
            "        [  0,   3,  10],\n",
            "        [  0,   1,   9],\n",
            "        [  0,   4,  11]],\n",
            "\n",
            "       [[  8,   3,  12],\n",
            "        [  9,   4,  13],\n",
            "        [  9,   4,  13],\n",
            "        ...,\n",
            "        [  0,   1,   4],\n",
            "        [  0,   3,   6],\n",
            "        [  1,   1,   4]],\n",
            "\n",
            "       [[  6,   0,  10],\n",
            "        [  7,   1,  11],\n",
            "        [  8,   2,  13],\n",
            "        ...,\n",
            "        [  5,   5,   5],\n",
            "        [  4,   4,   4],\n",
            "        [  4,   4,   4]]], dtype=uint8)\n",
            "orig_shape: (267, 400)\n",
            "path: '/content/yolo_datasets/images/val/road55.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 3.095358000109627, 'inference': 10.274960000060673, 'postprocess': 0.7401959999242536}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[220, 196, 135],\n",
            "        [221, 194, 136],\n",
            "        [222, 196, 137],\n",
            "        ...,\n",
            "        [226, 197, 137],\n",
            "        [226, 197, 137],\n",
            "        [226, 197, 137]],\n",
            "\n",
            "       [[220, 195, 136],\n",
            "        [222, 194, 138],\n",
            "        [221, 193, 138],\n",
            "        ...,\n",
            "        [226, 197, 137],\n",
            "        [226, 197, 137],\n",
            "        [226, 197, 137]],\n",
            "\n",
            "       [[220, 193, 137],\n",
            "        [222, 194, 139],\n",
            "        [221, 192, 139],\n",
            "        ...,\n",
            "        [227, 198, 138],\n",
            "        [226, 197, 137],\n",
            "        [226, 197, 137]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[214, 220, 207],\n",
            "        [206, 211, 198],\n",
            "        [114, 119, 108],\n",
            "        ...,\n",
            "        [ 67,  72,  60],\n",
            "        [ 72,  76,  64],\n",
            "        [ 68,  73,  61]],\n",
            "\n",
            "       [[121, 124, 111],\n",
            "        [185, 187, 175],\n",
            "        [159, 163, 151],\n",
            "        ...,\n",
            "        [ 65,  69,  58],\n",
            "        [ 66,  70,  58],\n",
            "        [ 78,  82,  70]],\n",
            "\n",
            "       [[ 13,  17,   2],\n",
            "        [126, 129, 116],\n",
            "        [184, 187, 174],\n",
            "        ...,\n",
            "        [ 65,  72,  58],\n",
            "        [ 59,  67,  52],\n",
            "        [ 86,  93,  79]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road551.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 4.181116999916412, 'inference': 11.440438000136055, 'postprocess': 0.7843549999506649}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[221, 180, 105],\n",
            "        [222, 178, 106],\n",
            "        [221, 177, 105],\n",
            "        ...,\n",
            "        [186, 172, 142],\n",
            "        [186, 172, 141],\n",
            "        [184, 170, 140]],\n",
            "\n",
            "       [[220, 178, 104],\n",
            "        [222, 178, 106],\n",
            "        [222, 178, 106],\n",
            "        ...,\n",
            "        [183, 168, 134],\n",
            "        [184, 168, 134],\n",
            "        [183, 168, 134]],\n",
            "\n",
            "       [[221, 179, 105],\n",
            "        [222, 178, 106],\n",
            "        [221, 177, 105],\n",
            "        ...,\n",
            "        [188, 170, 135],\n",
            "        [188, 170, 135],\n",
            "        [183, 164, 130]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 99, 152, 192],\n",
            "        [ 99, 151, 193],\n",
            "        [ 96, 149, 190],\n",
            "        ...,\n",
            "        [159, 165, 155],\n",
            "        [126, 131, 122],\n",
            "        [123, 127, 119]],\n",
            "\n",
            "       [[ 92, 146, 188],\n",
            "        [ 94, 147, 190],\n",
            "        [ 96, 149, 191],\n",
            "        ...,\n",
            "        [151, 158, 148],\n",
            "        [115, 123, 113],\n",
            "        [115, 123, 113]],\n",
            "\n",
            "       [[ 93, 149, 190],\n",
            "        [ 93, 147, 189],\n",
            "        [ 90, 144, 186],\n",
            "        ...,\n",
            "        [138, 148, 135],\n",
            "        [105, 117, 104],\n",
            "        [102, 115, 102]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road562.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6735140000037063, 'inference': 5.916316000138977, 'postprocess': 0.5321630001162703}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[220, 186, 124],\n",
            "        [222, 185, 125],\n",
            "        [222, 185, 125],\n",
            "        ...,\n",
            "        [220, 184, 125],\n",
            "        [220, 184, 125],\n",
            "        [220, 184, 125]],\n",
            "\n",
            "       [[221, 186, 124],\n",
            "        [222, 185, 125],\n",
            "        [222, 185, 125],\n",
            "        ...,\n",
            "        [217, 184, 125],\n",
            "        [217, 184, 125],\n",
            "        [217, 184, 125]],\n",
            "\n",
            "       [[221, 186, 124],\n",
            "        [222, 185, 125],\n",
            "        [222, 185, 125],\n",
            "        ...,\n",
            "        [217, 184, 125],\n",
            "        [217, 184, 125],\n",
            "        [217, 184, 125]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 50,  42,  20],\n",
            "        [ 45,  35,  15],\n",
            "        [ 46,  37,  17],\n",
            "        ...,\n",
            "        [117, 125, 115],\n",
            "        [182, 188, 177],\n",
            "        [ 21,  22,  13]],\n",
            "\n",
            "       [[ 45,  38,  14],\n",
            "        [ 47,  39,  16],\n",
            "        [ 47,  40,  17],\n",
            "        ...,\n",
            "        [116, 124, 114],\n",
            "        [178, 184, 173],\n",
            "        [ 21,  23,  14]],\n",
            "\n",
            "       [[ 32,  26,   4],\n",
            "        [ 33,  25,   4],\n",
            "        [ 34,  26,   5],\n",
            "        ...,\n",
            "        [114, 126, 112],\n",
            "        [180, 189, 175],\n",
            "        [ 17,  22,  13]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road569.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7454320000069856, 'inference': 6.074694000062664, 'postprocess': 0.4863240001213853}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[215, 169,  97],\n",
            "        [217, 168,  98],\n",
            "        [217, 168,  98],\n",
            "        ...,\n",
            "        [209, 160,  97],\n",
            "        [207, 161,  96],\n",
            "        [206, 161,  96]],\n",
            "\n",
            "       [[216, 169,  97],\n",
            "        [217, 168,  98],\n",
            "        [217, 168,  98],\n",
            "        ...,\n",
            "        [208, 160,  96],\n",
            "        [207, 161,  96],\n",
            "        [207, 161,  96]],\n",
            "\n",
            "       [[216, 169,  97],\n",
            "        [217, 168,  98],\n",
            "        [217, 168,  98],\n",
            "        ...,\n",
            "        [207, 161,  96],\n",
            "        [207, 161,  96],\n",
            "        [207, 161,  96]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[100, 116, 101],\n",
            "        [ 98, 113,  98],\n",
            "        [ 95, 110,  96],\n",
            "        ...,\n",
            "        [ 69,  73,  56],\n",
            "        [ 70,  72,  55],\n",
            "        [ 70,  72,  56]],\n",
            "\n",
            "       [[ 98, 114,  99],\n",
            "        [ 99, 113,  99],\n",
            "        [ 97, 111,  97],\n",
            "        ...,\n",
            "        [115, 121, 106],\n",
            "        [115, 120, 105],\n",
            "        [115, 120, 105]],\n",
            "\n",
            "       [[ 97, 113,  98],\n",
            "        [ 99, 115, 100],\n",
            "        [ 97, 113,  98],\n",
            "        ...,\n",
            "        [186, 195, 176],\n",
            "        [186, 193, 176],\n",
            "        [187, 193, 175]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road572.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7483350000020437, 'inference': 5.90146299987282, 'postprocess': 0.504997000007279}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[206, 156,  82],\n",
            "        [208, 154,  83],\n",
            "        [208, 154,  83],\n",
            "        ...,\n",
            "        [192, 142,  75],\n",
            "        [192, 142,  74],\n",
            "        [192, 142,  75]],\n",
            "\n",
            "       [[206, 153,  82],\n",
            "        [208, 154,  83],\n",
            "        [208, 154,  83],\n",
            "        ...,\n",
            "        [192, 142,  74],\n",
            "        [192, 142,  75],\n",
            "        [192, 143,  73]],\n",
            "\n",
            "       [[206, 155,  82],\n",
            "        [208, 154,  84],\n",
            "        [208, 154,  84],\n",
            "        ...,\n",
            "        [192, 142,  75],\n",
            "        [192, 142,  74],\n",
            "        [192, 142,  74]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[188, 169, 130],\n",
            "        [189, 170, 132],\n",
            "        [189, 171, 132],\n",
            "        ...,\n",
            "        [133, 118,  77],\n",
            "        [149, 147, 119],\n",
            "        [232, 242, 220]],\n",
            "\n",
            "       [[190, 172, 131],\n",
            "        [189, 171, 131],\n",
            "        [190, 172, 132],\n",
            "        ...,\n",
            "        [120, 108,  73],\n",
            "        [214, 218, 195],\n",
            "        [233, 244, 226]],\n",
            "\n",
            "       [[191, 174, 132],\n",
            "        [187, 169, 128],\n",
            "        [190, 172, 131],\n",
            "        ...,\n",
            "        [131, 124,  89],\n",
            "        [233, 244, 218],\n",
            "        [235, 247, 224]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road574.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.8016179999449378, 'inference': 5.943865999824993, 'postprocess': 0.4654429999391141}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[188, 145,  86],\n",
            "        [190, 143,  88],\n",
            "        [190, 142,  89],\n",
            "        ...,\n",
            "        [181, 134,  83],\n",
            "        [180, 135,  87],\n",
            "        [182, 136,  89]],\n",
            "\n",
            "       [[189, 145,  86],\n",
            "        [190, 142,  87],\n",
            "        [189, 141,  88],\n",
            "        ...,\n",
            "        [180, 134,  84],\n",
            "        [179, 136,  88],\n",
            "        [180, 136,  87]],\n",
            "\n",
            "       [[191, 144,  86],\n",
            "        [191, 142,  86],\n",
            "        [190, 142,  86],\n",
            "        ...,\n",
            "        [183, 135,  85],\n",
            "        [181, 136,  87],\n",
            "        [180, 137,  87]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[147, 165, 154],\n",
            "        [147, 164, 153],\n",
            "        [143, 159, 148],\n",
            "        ...,\n",
            "        [ 59,  74,  66],\n",
            "        [ 45,  55,  47],\n",
            "        [ 63,  73,  65]],\n",
            "\n",
            "       [[147, 163, 152],\n",
            "        [142, 157, 147],\n",
            "        [145, 161, 150],\n",
            "        ...,\n",
            "        [ 73,  87,  78],\n",
            "        [ 74,  87,  77],\n",
            "        [ 67,  78,  67]],\n",
            "\n",
            "       [[140, 157, 144],\n",
            "        [144, 160, 149],\n",
            "        [148, 165, 151],\n",
            "        ...,\n",
            "        [ 43,  59,  46],\n",
            "        [ 81,  99,  86],\n",
            "        [ 45,  59,  46]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road575.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7293309999786288, 'inference': 6.206410000004325, 'postprocess': 0.4806599999938044}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[204, 144,  53],\n",
            "        [205, 142,  52],\n",
            "        [204, 142,  52],\n",
            "        ...,\n",
            "        [181, 160,  63],\n",
            "        [182, 161,  63],\n",
            "        [182, 161,  63]],\n",
            "\n",
            "       [[204, 144,  53],\n",
            "        [205, 143,  53],\n",
            "        [205, 143,  53],\n",
            "        ...,\n",
            "        [182, 161,  63],\n",
            "        [181, 160,  62],\n",
            "        [181, 160,  62]],\n",
            "\n",
            "       [[205, 142,  53],\n",
            "        [205, 141,  53],\n",
            "        [206, 142,  53],\n",
            "        ...,\n",
            "        [179, 157,  61],\n",
            "        [180, 159,  62],\n",
            "        [179, 158,  62]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[134, 142, 128],\n",
            "        [133, 140, 127],\n",
            "        [137, 144, 131],\n",
            "        ...,\n",
            "        [ 78,  64,  41],\n",
            "        [ 96,  81,  55],\n",
            "        [116,  99,  70]],\n",
            "\n",
            "       [[135, 143, 129],\n",
            "        [137, 144, 131],\n",
            "        [139, 146, 133],\n",
            "        ...,\n",
            "        [ 90,  74,  51],\n",
            "        [116,  99,  69],\n",
            "        [121, 103,  73]],\n",
            "\n",
            "       [[150, 159, 144],\n",
            "        [149, 156, 142],\n",
            "        [148, 155, 141],\n",
            "        ...,\n",
            "        [107,  93,  64],\n",
            "        [119, 104,  71],\n",
            "        [118, 103,  70]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road578.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7052489999969112, 'inference': 6.020019000061438, 'postprocess': 0.4622670001026563}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[198, 177, 140],\n",
            "        [200, 175, 142],\n",
            "        [199, 174, 141],\n",
            "        ...,\n",
            "        [204, 187, 159],\n",
            "        [205, 188, 160],\n",
            "        [206, 189, 161]],\n",
            "\n",
            "       [[198, 176, 141],\n",
            "        [200, 175, 142],\n",
            "        [200, 175, 142],\n",
            "        ...,\n",
            "        [210, 193, 165],\n",
            "        [209, 194, 165],\n",
            "        [209, 195, 166]],\n",
            "\n",
            "       [[199, 175, 141],\n",
            "        [200, 175, 142],\n",
            "        [200, 175, 142],\n",
            "        ...,\n",
            "        [212, 197, 170],\n",
            "        [212, 198, 170],\n",
            "        [213, 198, 171]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[131, 138, 129],\n",
            "        [130, 137, 128],\n",
            "        [128, 136, 126],\n",
            "        ...,\n",
            "        [ 92,  99,  93],\n",
            "        [114, 120, 113],\n",
            "        [ 95, 101,  94]],\n",
            "\n",
            "       [[126, 134, 124],\n",
            "        [125, 133, 123],\n",
            "        [128, 136, 126],\n",
            "        ...,\n",
            "        [112, 118, 112],\n",
            "        [ 80,  83,  74],\n",
            "        [ 87,  91,  82]],\n",
            "\n",
            "       [[131, 141, 129],\n",
            "        [131, 139, 129],\n",
            "        [127, 135, 125],\n",
            "        ...,\n",
            "        [ 97, 107,  97],\n",
            "        [ 71,  77,  66],\n",
            "        [ 74,  81,  68]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road580.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7789510000056907, 'inference': 5.892347999861158, 'postprocess': 0.47186599999804457}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[216, 166,  95],\n",
            "        [218, 165,  98],\n",
            "        [218, 165,  98],\n",
            "        ...,\n",
            "        [227, 191, 127],\n",
            "        [227, 191, 127],\n",
            "        [227, 191, 127]],\n",
            "\n",
            "       [[217, 166,  95],\n",
            "        [218, 165,  98],\n",
            "        [218, 165,  98],\n",
            "        ...,\n",
            "        [227, 191, 127],\n",
            "        [227, 191, 127],\n",
            "        [227, 191, 127]],\n",
            "\n",
            "       [[217, 165,  97],\n",
            "        [218, 165,  98],\n",
            "        [217, 165,  98],\n",
            "        ...,\n",
            "        [226, 190, 126],\n",
            "        [227, 191, 127],\n",
            "        [227, 191, 127]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[108, 115,  97],\n",
            "        [108, 114,  97],\n",
            "        [108, 114,  97],\n",
            "        ...,\n",
            "        [158, 181, 166],\n",
            "        [158, 180, 166],\n",
            "        [156, 175, 162]],\n",
            "\n",
            "       [[107, 114,  96],\n",
            "        [109, 115,  98],\n",
            "        [111, 118, 100],\n",
            "        ...,\n",
            "        [ 86,  98,  84],\n",
            "        [ 77,  87,  74],\n",
            "        [ 68,  75,  63]],\n",
            "\n",
            "       [[109, 117,  97],\n",
            "        [107, 115,  95],\n",
            "        [110, 118,  99],\n",
            "        ...,\n",
            "        [ 70,  79,  63],\n",
            "        [ 67,  76,  61],\n",
            "        [ 78,  84,  69]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road583.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.70395599980111, 'inference': 7.018401000095764, 'postprocess': 0.46707000001333654}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[199, 167, 110],\n",
            "        [201, 166, 109],\n",
            "        [202, 164, 108],\n",
            "        ...,\n",
            "        [188, 131,  61],\n",
            "        [189, 132,  62],\n",
            "        [188, 131,  60]],\n",
            "\n",
            "       [[199, 167, 110],\n",
            "        [201, 165, 109],\n",
            "        [203, 166, 109],\n",
            "        ...,\n",
            "        [189, 132,  61],\n",
            "        [189, 132,  61],\n",
            "        [189, 132,  61]],\n",
            "\n",
            "       [[202, 166, 109],\n",
            "        [203, 166, 109],\n",
            "        [203, 165, 108],\n",
            "        ...,\n",
            "        [189, 132,  61],\n",
            "        [189, 132,  62],\n",
            "        [188, 131,  61]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[131, 115,  74],\n",
            "        [126, 109,  70],\n",
            "        [121, 102,  64],\n",
            "        ...,\n",
            "        [ 53,  44,  18],\n",
            "        [ 51,  40,  15],\n",
            "        [ 55,  43,  18]],\n",
            "\n",
            "       [[129, 113,  72],\n",
            "        [127, 109,  71],\n",
            "        [124, 105,  67],\n",
            "        ...,\n",
            "        [ 63,  55,  27],\n",
            "        [ 65,  55,  29],\n",
            "        [ 62,  52,  27]],\n",
            "\n",
            "       [[127, 112,  70],\n",
            "        [121, 105,  66],\n",
            "        [121, 102,  66],\n",
            "        ...,\n",
            "        [ 56,  51,  20],\n",
            "        [ 59,  53,  24],\n",
            "        [ 60,  54,  26]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road584.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.1467429999120213, 'inference': 5.948477000174535, 'postprocess': 0.503508000065267}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[215, 183, 114],\n",
            "        [218, 182, 116],\n",
            "        [218, 182, 116],\n",
            "        ...,\n",
            "        [223, 183, 116],\n",
            "        [222, 182, 115],\n",
            "        [222, 182, 115]],\n",
            "\n",
            "       [[216, 183, 115],\n",
            "        [218, 182, 116],\n",
            "        [218, 182, 117],\n",
            "        ...,\n",
            "        [223, 183, 116],\n",
            "        [222, 182, 115],\n",
            "        [222, 182, 115]],\n",
            "\n",
            "       [[219, 183, 119],\n",
            "        [220, 184, 120],\n",
            "        [219, 183, 120],\n",
            "        ...,\n",
            "        [222, 182, 115],\n",
            "        [223, 183, 116],\n",
            "        [223, 183, 116]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 73,  66,  48],\n",
            "        [ 65,  57,  39],\n",
            "        [ 60,  53,  34],\n",
            "        ...,\n",
            "        [ 69,  55,  37],\n",
            "        [ 71,  58,  40],\n",
            "        [ 63,  50,  30]],\n",
            "\n",
            "       [[ 72,  66,  48],\n",
            "        [ 78,  71,  54],\n",
            "        [ 66,  58,  41],\n",
            "        ...,\n",
            "        [ 65,  53,  35],\n",
            "        [ 80,  69,  51],\n",
            "        [ 61,  49,  31]],\n",
            "\n",
            "       [[ 68,  63,  46],\n",
            "        [ 84,  78,  62],\n",
            "        [ 81,  74,  58],\n",
            "        ...,\n",
            "        [ 86,  79,  57],\n",
            "        [129, 124, 105],\n",
            "        [ 63,  58,  41]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road591.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7172529999243125, 'inference': 5.8959259999937785, 'postprocess': 0.48471800005245314}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[221, 199, 138],\n",
            "        [223, 198, 140],\n",
            "        [223, 198, 140],\n",
            "        ...,\n",
            "        [236, 241, 219],\n",
            "        [237, 242, 222],\n",
            "        [235, 239, 220]],\n",
            "\n",
            "       [[222, 198, 139],\n",
            "        [223, 198, 140],\n",
            "        [223, 198, 140],\n",
            "        ...,\n",
            "        [235, 240, 219],\n",
            "        [235, 239, 219],\n",
            "        [236, 240, 221]],\n",
            "\n",
            "       [[222, 198, 139],\n",
            "        [223, 198, 140],\n",
            "        [223, 198, 140],\n",
            "        ...,\n",
            "        [234, 239, 217],\n",
            "        [232, 236, 216],\n",
            "        [234, 237, 217]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[106, 109,  89],\n",
            "        [107, 109,  90],\n",
            "        [108, 109,  93],\n",
            "        ...,\n",
            "        [ 92, 112, 103],\n",
            "        [ 94, 114, 105],\n",
            "        [ 94, 114, 105]],\n",
            "\n",
            "       [[104, 107,  88],\n",
            "        [108, 110,  90],\n",
            "        [106, 107,  89],\n",
            "        ...,\n",
            "        [ 91, 110, 101],\n",
            "        [ 94, 113, 104],\n",
            "        [ 95, 114, 105]],\n",
            "\n",
            "       [[103, 107,  87],\n",
            "        [106, 109,  90],\n",
            "        [107, 110,  91],\n",
            "        ...,\n",
            "        [ 87, 108,  97],\n",
            "        [ 88, 108,  98],\n",
            "        [ 83, 103,  93]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road597.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.8383249998805695, 'inference': 5.941517000110252, 'postprocess': 0.48720399990997976}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[216, 175, 102],\n",
            "        [218, 174, 103],\n",
            "        [218, 174, 103],\n",
            "        ...,\n",
            "        [224, 178, 106],\n",
            "        [224, 178, 106],\n",
            "        [225, 179, 107]],\n",
            "\n",
            "       [[217, 175, 102],\n",
            "        [218, 174, 103],\n",
            "        [218, 174, 103],\n",
            "        ...,\n",
            "        [224, 178, 106],\n",
            "        [224, 178, 106],\n",
            "        [224, 178, 106]],\n",
            "\n",
            "       [[217, 174, 102],\n",
            "        [218, 174, 103],\n",
            "        [218, 174, 103],\n",
            "        ...,\n",
            "        [224, 178, 106],\n",
            "        [225, 179, 107],\n",
            "        [225, 179, 107]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 69,  72,  58],\n",
            "        [ 67,  68,  56],\n",
            "        [ 54,  54,  39],\n",
            "        ...,\n",
            "        [ 72,  71,  59],\n",
            "        [ 54,  56,  45],\n",
            "        [ 55,  59,  48]],\n",
            "\n",
            "       [[ 56,  58,  43],\n",
            "        [ 56,  56,  42],\n",
            "        [ 53,  53,  38],\n",
            "        ...,\n",
            "        [ 50,  50,  37],\n",
            "        [ 54,  56,  46],\n",
            "        [ 58,  61,  51]],\n",
            "\n",
            "       [[ 46,  48,  32],\n",
            "        [ 52,  53,  38],\n",
            "        [ 56,  57,  42],\n",
            "        ...,\n",
            "        [ 48,  51,  35],\n",
            "        [ 69,  74,  61],\n",
            "        [ 59,  65,  54]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road599.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.8035370001143747, 'inference': 5.965994000007413, 'postprocess': 0.4825349999464379}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[216, 194, 137],\n",
            "        [217, 193, 139],\n",
            "        [217, 193, 139],\n",
            "        ...,\n",
            "        [221, 222, 202],\n",
            "        [222, 223, 202],\n",
            "        [218, 219, 199]],\n",
            "\n",
            "       [[216, 194, 138],\n",
            "        [217, 193, 139],\n",
            "        [217, 193, 139],\n",
            "        ...,\n",
            "        [223, 225, 205],\n",
            "        [225, 226, 207],\n",
            "        [222, 224, 204]],\n",
            "\n",
            "       [[216, 193, 138],\n",
            "        [217, 193, 139],\n",
            "        [217, 193, 139],\n",
            "        ...,\n",
            "        [231, 233, 214],\n",
            "        [232, 234, 214],\n",
            "        [231, 233, 213]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[106, 107,  91],\n",
            "        [105, 105,  89],\n",
            "        [102, 103,  87],\n",
            "        ...,\n",
            "        [160, 193, 194],\n",
            "        [157, 191, 191],\n",
            "        [159, 192, 193]],\n",
            "\n",
            "       [[102, 102,  85],\n",
            "        [105, 106,  89],\n",
            "        [104, 105,  89],\n",
            "        ...,\n",
            "        [163, 197, 197],\n",
            "        [161, 194, 195],\n",
            "        [158, 192, 193]],\n",
            "\n",
            "       [[107, 108,  90],\n",
            "        [104, 106,  88],\n",
            "        [ 97, 100,  81],\n",
            "        ...,\n",
            "        [159, 195, 194],\n",
            "        [162, 198, 197],\n",
            "        [159, 195, 194]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road602.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.723043999845686, 'inference': 5.894121999972413, 'postprocess': 0.5598879999979545}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[116, 104,  72],\n",
            "        [186, 177, 148],\n",
            "        [179, 172, 142],\n",
            "        ...,\n",
            "        [210, 220, 216],\n",
            "        [ 73,  74,  70],\n",
            "        [ 61,  58,  50]],\n",
            "\n",
            "       [[153, 151, 117],\n",
            "        [156, 146, 117],\n",
            "        [120, 110,  81],\n",
            "        ...,\n",
            "        [227, 236, 233],\n",
            "        [ 88,  91,  87],\n",
            "        [ 74,  71,  64]],\n",
            "\n",
            "       [[156, 150, 117],\n",
            "        [187, 179, 148],\n",
            "        [174, 165, 133],\n",
            "        ...,\n",
            "        [211, 222, 218],\n",
            "        [112, 117, 114],\n",
            "        [ 69,  62,  59]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 93, 114, 108],\n",
            "        [ 83, 102,  98],\n",
            "        [ 80, 100,  95],\n",
            "        ...,\n",
            "        [ 96, 123, 120],\n",
            "        [ 93, 120, 117],\n",
            "        [ 89, 116, 113]],\n",
            "\n",
            "       [[ 83, 102,  96],\n",
            "        [ 83, 100,  96],\n",
            "        [ 81, 101,  96],\n",
            "        ...,\n",
            "        [ 96, 122, 120],\n",
            "        [ 73, 100,  97],\n",
            "        [ 79, 105, 103]],\n",
            "\n",
            "       [[ 77,  96,  90],\n",
            "        [ 80,  98,  93],\n",
            "        [ 79,  99,  93],\n",
            "        ...,\n",
            "        [120, 151, 145],\n",
            "        [ 75, 104, 100],\n",
            "        [ 84, 113, 108]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road606.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6841209999256535, 'inference': 5.90511899986268, 'postprocess': 0.48475400012648606}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 60,  51,  35],\n",
            "        [ 65,  51,  38],\n",
            "        [ 59,  45,  34],\n",
            "        ...,\n",
            "        [148, 115,  97],\n",
            "        [250, 217, 188],\n",
            "        [247, 220, 184]],\n",
            "\n",
            "       [[ 66,  57,  41],\n",
            "        [ 67,  55,  42],\n",
            "        [ 61,  48,  35],\n",
            "        ...,\n",
            "        [134, 103,  86],\n",
            "        [240, 209, 183],\n",
            "        [252, 236, 201]],\n",
            "\n",
            "       [[ 76,  66,  49],\n",
            "        [ 74,  62,  47],\n",
            "        [ 63,  50,  37],\n",
            "        ...,\n",
            "        [105,  78,  65],\n",
            "        [194, 160, 139],\n",
            "        [254, 243, 210]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 99,  92,  87],\n",
            "        [101,  92,  88],\n",
            "        [104,  95,  90],\n",
            "        ...,\n",
            "        [ 99,  87,  78],\n",
            "        [ 95,  83,  74],\n",
            "        [ 92,  80,  71]],\n",
            "\n",
            "       [[ 93,  86,  80],\n",
            "        [ 93,  84,  80],\n",
            "        [ 97,  89,  81],\n",
            "        ...,\n",
            "        [ 92,  80,  72],\n",
            "        [ 97,  84,  75],\n",
            "        [ 99,  84,  76]],\n",
            "\n",
            "       [[ 94,  88,  81],\n",
            "        [ 94,  86,  81],\n",
            "        [ 93,  86,  77],\n",
            "        ...,\n",
            "        [ 90,  81,  70],\n",
            "        [ 99,  86,  77],\n",
            "        [101,  88,  79]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road610.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.8233450000479934, 'inference': 5.908134000037535, 'postprocess': 0.4828480000469426}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 66,  53,  42],\n",
            "        [ 70,  53,  44],\n",
            "        [ 71,  57,  51],\n",
            "        ...,\n",
            "        [ 84,  66,  54],\n",
            "        [ 79,  62,  50],\n",
            "        [ 79,  62,  49]],\n",
            "\n",
            "       [[ 67,  52,  41],\n",
            "        [ 69,  52,  42],\n",
            "        [ 64,  51,  41],\n",
            "        ...,\n",
            "        [ 83,  66,  54],\n",
            "        [ 84,  66,  54],\n",
            "        [ 82,  64,  50]],\n",
            "\n",
            "       [[ 73,  55,  45],\n",
            "        [ 71,  53,  44],\n",
            "        [ 56,  41,  32],\n",
            "        ...,\n",
            "        [ 81,  64,  52],\n",
            "        [ 85,  67,  55],\n",
            "        [ 83,  64,  50]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 85,  86,  72],\n",
            "        [ 83,  83,  70],\n",
            "        [ 79,  79,  66],\n",
            "        ...,\n",
            "        [100,  91,  87],\n",
            "        [101,  92,  88],\n",
            "        [104,  95,  91]],\n",
            "\n",
            "       [[ 82,  84,  68],\n",
            "        [ 80,  80,  65],\n",
            "        [ 82,  82,  68],\n",
            "        ...,\n",
            "        [ 89,  82,  77],\n",
            "        [ 95,  88,  83],\n",
            "        [107, 101,  96]],\n",
            "\n",
            "       [[ 81,  84,  67],\n",
            "        [ 79,  80,  65],\n",
            "        [ 80,  82,  67],\n",
            "        ...,\n",
            "        [ 82,  79,  72],\n",
            "        [ 83,  80,  73],\n",
            "        [ 98,  96,  89]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road611.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7540349999762839, 'inference': 5.910267999979624, 'postprocess': 0.4903310000372585}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[217, 208, 190],\n",
            "        [223, 210, 196],\n",
            "        [223, 211, 199],\n",
            "        ...,\n",
            "        [109, 137, 149],\n",
            "        [121, 151, 160],\n",
            "        [152, 174, 178]],\n",
            "\n",
            "       [[220, 210, 193],\n",
            "        [224, 211, 197],\n",
            "        [223, 211, 199],\n",
            "        ...,\n",
            "        [108, 135, 149],\n",
            "        [112, 137, 147],\n",
            "        [124, 144, 150]],\n",
            "\n",
            "       [[223, 209, 196],\n",
            "        [224, 211, 198],\n",
            "        [224, 214, 201],\n",
            "        ...,\n",
            "        [130, 151, 159],\n",
            "        [135, 149, 156],\n",
            "        [156, 166, 173]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[118,  99,  74],\n",
            "        [118,  99,  74],\n",
            "        [119,  98,  74],\n",
            "        ...,\n",
            "        [ 94,  82,  67],\n",
            "        [ 95,  84,  69],\n",
            "        [ 95,  84,  69]],\n",
            "\n",
            "       [[117,  99,  73],\n",
            "        [118,  99,  74],\n",
            "        [116,  97,  72],\n",
            "        ...,\n",
            "        [100,  88,  73],\n",
            "        [ 98,  86,  71],\n",
            "        [ 97,  86,  71]],\n",
            "\n",
            "       [[118, 100,  73],\n",
            "        [116,  98,  72],\n",
            "        [115,  96,  71],\n",
            "        ...,\n",
            "        [ 98,  89,  72],\n",
            "        [ 98,  89,  71],\n",
            "        [ 99,  89,  72]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road613.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7039889999068691, 'inference': 5.994051000016043, 'postprocess': 0.4704839998339594}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[181, 140,  93],\n",
            "        [248, 235, 189],\n",
            "        [200, 159, 122],\n",
            "        ...,\n",
            "        [248, 215, 157],\n",
            "        [248, 216, 156],\n",
            "        [250, 218, 158]],\n",
            "\n",
            "       [[184, 142,  89],\n",
            "        [233, 204, 149],\n",
            "        [204, 162, 118],\n",
            "        ...,\n",
            "        [248, 215, 158],\n",
            "        [248, 216, 158],\n",
            "        [250, 217, 159]],\n",
            "\n",
            "       [[222, 184, 138],\n",
            "        [237, 215, 164],\n",
            "        [229, 193, 141],\n",
            "        ...,\n",
            "        [248, 216, 158],\n",
            "        [249, 215, 159],\n",
            "        [249, 216, 159]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[111,  95,  74],\n",
            "        [113,  97,  76],\n",
            "        [115,  98,  77],\n",
            "        ...,\n",
            "        [ 89,  80,  66],\n",
            "        [ 89,  81,  66],\n",
            "        [ 89,  81,  66]],\n",
            "\n",
            "       [[113,  98,  77],\n",
            "        [115,  99,  78],\n",
            "        [115,  99,  78],\n",
            "        ...,\n",
            "        [ 92,  83,  68],\n",
            "        [ 89,  81,  63],\n",
            "        [ 85,  77,  59]],\n",
            "\n",
            "       [[114, 100,  78],\n",
            "        [114,  98,  77],\n",
            "        [115,  99,  78],\n",
            "        ...,\n",
            "        [ 89,  84,  66],\n",
            "        [ 94,  89,  68],\n",
            "        [ 91,  86,  65]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road619.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.710629999934099, 'inference': 5.887839000024542, 'postprocess': 0.4820859999199456}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 64,  56,  52],\n",
            "        [ 64,  56,  52],\n",
            "        [ 64,  56,  52],\n",
            "        ...,\n",
            "        [ 64,  55,  49],\n",
            "        [ 64,  55,  49],\n",
            "        [ 64,  55,  49]],\n",
            "\n",
            "       [[ 64,  56,  52],\n",
            "        [ 64,  56,  52],\n",
            "        [ 64,  56,  52],\n",
            "        ...,\n",
            "        [ 64,  55,  49],\n",
            "        [ 64,  55,  49],\n",
            "        [ 64,  55,  49]],\n",
            "\n",
            "       [[ 64,  56,  52],\n",
            "        [ 64,  56,  52],\n",
            "        [ 64,  56,  52],\n",
            "        ...,\n",
            "        [ 64,  55,  49],\n",
            "        [ 64,  55,  49],\n",
            "        [ 64,  55,  49]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 99,  99, 106],\n",
            "        [ 98,  98, 105],\n",
            "        [ 95,  95, 102],\n",
            "        ...,\n",
            "        [ 98, 103, 112],\n",
            "        [ 98, 103, 112],\n",
            "        [ 98, 103, 112]],\n",
            "\n",
            "       [[ 95,  95, 102],\n",
            "        [ 95,  95, 101],\n",
            "        [ 94,  94, 100],\n",
            "        ...,\n",
            "        [ 97, 103, 113],\n",
            "        [ 97, 103, 113],\n",
            "        [ 97, 102, 113]],\n",
            "\n",
            "       [[ 94,  94, 101],\n",
            "        [ 94,  94, 100],\n",
            "        [ 93,  93, 100],\n",
            "        ...,\n",
            "        [ 97, 102, 113],\n",
            "        [ 97, 102, 113],\n",
            "        [ 97, 102, 113]]], dtype=uint8)\n",
            "orig_shape: (400, 267)\n",
            "path: '/content/yolo_datasets/images/val/road62.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.936333999992712, 'inference': 6.411716999991768, 'postprocess': 0.4755039999508881}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[104,  89,  59],\n",
            "        [108,  89,  62],\n",
            "        [111,  91,  65],\n",
            "        ...,\n",
            "        [145, 137, 112],\n",
            "        [150, 143, 117],\n",
            "        [151, 144, 119]],\n",
            "\n",
            "       [[106,  90,  60],\n",
            "        [109,  89,  63],\n",
            "        [111,  91,  64],\n",
            "        ...,\n",
            "        [137, 130, 104],\n",
            "        [141, 134, 108],\n",
            "        [137, 130, 105]],\n",
            "\n",
            "       [[111,  93,  66],\n",
            "        [113,  93,  67],\n",
            "        [110,  91,  65],\n",
            "        ...,\n",
            "        [140, 133, 107],\n",
            "        [146, 139, 113],\n",
            "        [146, 139, 113]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[156, 158, 147],\n",
            "        [152, 153, 143],\n",
            "        [146, 147, 137],\n",
            "        ...,\n",
            "        [116, 114, 103],\n",
            "        [120, 118, 107],\n",
            "        [128, 126, 115]],\n",
            "\n",
            "       [[156, 159, 147],\n",
            "        [151, 152, 142],\n",
            "        [152, 153, 143],\n",
            "        ...,\n",
            "        [129, 126, 115],\n",
            "        [111, 109,  97],\n",
            "        [118, 115, 104]],\n",
            "\n",
            "       [[161, 164, 152],\n",
            "        [155, 158, 146],\n",
            "        [154, 156, 144],\n",
            "        ...,\n",
            "        [115, 115, 100],\n",
            "        [104, 103,  89],\n",
            "        [ 92,  91,  77]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road631.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.590897999903973, 'inference': 6.493571999953929, 'postprocess': 0.4453860001376597}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[106,  95,  69],\n",
            "        [115, 103,  80],\n",
            "        [103,  93,  70],\n",
            "        ...,\n",
            "        [ 96,  91,  76],\n",
            "        [ 93,  85,  70],\n",
            "        [ 96,  90,  71]],\n",
            "\n",
            "       [[ 96,  84,  59],\n",
            "        [117, 106,  82],\n",
            "        [106,  96,  73],\n",
            "        ...,\n",
            "        [ 89,  85,  70],\n",
            "        [139, 133, 111],\n",
            "        [243, 243, 223]],\n",
            "\n",
            "       [[103,  92,  67],\n",
            "        [115, 104,  81],\n",
            "        [112, 101,  79],\n",
            "        ...,\n",
            "        [ 92,  88,  72],\n",
            "        [124, 119,  99],\n",
            "        [248, 245, 218]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[122, 130, 120],\n",
            "        [123, 130, 121],\n",
            "        [119, 127, 117],\n",
            "        ...,\n",
            "        [151, 167, 157],\n",
            "        [153, 170, 159],\n",
            "        [148, 165, 154]],\n",
            "\n",
            "       [[120, 128, 118],\n",
            "        [128, 136, 126],\n",
            "        [136, 144, 134],\n",
            "        ...,\n",
            "        [146, 162, 151],\n",
            "        [150, 166, 155],\n",
            "        [161, 177, 166]],\n",
            "\n",
            "       [[117, 126, 115],\n",
            "        [125, 133, 123],\n",
            "        [142, 149, 139],\n",
            "        ...,\n",
            "        [130, 147, 134],\n",
            "        [128, 146, 133],\n",
            "        [133, 151, 138]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road634.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.630937000072663, 'inference': 5.901598000036756, 'postprocess': 0.48959799983094854}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 73,  68,  61],\n",
            "        [ 75,  65,  61],\n",
            "        [ 73,  62,  57],\n",
            "        ...,\n",
            "        [ 93,  84,  80],\n",
            "        [ 97,  88,  84],\n",
            "        [ 99,  92,  87]],\n",
            "\n",
            "       [[ 74,  69,  62],\n",
            "        [ 74,  66,  61],\n",
            "        [ 72,  62,  57],\n",
            "        ...,\n",
            "        [ 93,  83,  79],\n",
            "        [ 91,  84,  81],\n",
            "        [ 98,  90,  86]],\n",
            "\n",
            "       [[ 76,  71,  64],\n",
            "        [ 74,  68,  62],\n",
            "        [ 74,  67,  61],\n",
            "        ...,\n",
            "        [ 94,  84,  80],\n",
            "        [ 93,  86,  83],\n",
            "        [ 96,  87,  84]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[166, 155, 145],\n",
            "        [166, 152, 145],\n",
            "        [162, 150, 144],\n",
            "        ...,\n",
            "        [167, 161, 155],\n",
            "        [167, 161, 155],\n",
            "        [167, 163, 157]],\n",
            "\n",
            "       [[166, 154, 145],\n",
            "        [166, 152, 145],\n",
            "        [162, 151, 145],\n",
            "        ...,\n",
            "        [180, 174, 168],\n",
            "        [179, 173, 168],\n",
            "        [179, 174, 168]],\n",
            "\n",
            "       [[165, 155, 144],\n",
            "        [165, 153, 144],\n",
            "        [162, 151, 145],\n",
            "        ...,\n",
            "        [180, 177, 170],\n",
            "        [179, 176, 169],\n",
            "        [179, 174, 166]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road641.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.805359000172757, 'inference': 5.931533999955718, 'postprocess': 0.4892239999207959}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[211, 207, 211],\n",
            "        [205, 202, 206],\n",
            "        [189, 185, 189],\n",
            "        ...,\n",
            "        [ 89,  84,  82],\n",
            "        [ 81,  77,  74],\n",
            "        [ 80,  76,  73]],\n",
            "\n",
            "       [[222, 218, 222],\n",
            "        [217, 213, 217],\n",
            "        [202, 198, 202],\n",
            "        ...,\n",
            "        [ 88,  84,  81],\n",
            "        [ 82,  78,  75],\n",
            "        [ 81,  77,  74]],\n",
            "\n",
            "       [[254, 251, 255],\n",
            "        [251, 247, 251],\n",
            "        [240, 237, 240],\n",
            "        ...,\n",
            "        [ 87,  83,  80],\n",
            "        [ 84,  79,  77],\n",
            "        [ 83,  79,  76]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[182, 185, 189],\n",
            "        [183, 186, 189],\n",
            "        [186, 188, 192],\n",
            "        ...,\n",
            "        [112, 113, 110],\n",
            "        [125, 126, 123],\n",
            "        [127, 128, 125]],\n",
            "\n",
            "       [[163, 165, 166],\n",
            "        [164, 166, 167],\n",
            "        [167, 169, 171],\n",
            "        ...,\n",
            "        [139, 140, 136],\n",
            "        [144, 146, 141],\n",
            "        [145, 147, 142]],\n",
            "\n",
            "       [[156, 158, 159],\n",
            "        [157, 159, 160],\n",
            "        [161, 163, 164],\n",
            "        ...,\n",
            "        [147, 149, 144],\n",
            "        [151, 152, 148],\n",
            "        [151, 153, 148]]], dtype=uint8)\n",
            "orig_shape: (400, 268)\n",
            "path: '/content/yolo_datasets/images/val/road65.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.186244000085935, 'inference': 6.472861999782253, 'postprocess': 0.44647699996858137}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[167, 153, 136],\n",
            "        [138, 118, 104],\n",
            "        [100,  81,  64],\n",
            "        ...,\n",
            "        [ 72,  56,  39],\n",
            "        [ 78,  63,  45],\n",
            "        [ 84,  68,  52]],\n",
            "\n",
            "       [[164, 150, 142],\n",
            "        [146, 127, 118],\n",
            "        [ 92,  74,  58],\n",
            "        ...,\n",
            "        [ 72,  56,  38],\n",
            "        [ 74,  59,  40],\n",
            "        [ 79,  63,  46]],\n",
            "\n",
            "       [[144, 127, 124],\n",
            "        [145, 127, 121],\n",
            "        [102,  83,  68],\n",
            "        ...,\n",
            "        [ 74,  58,  40],\n",
            "        [ 76,  60,  42],\n",
            "        [ 79,  64,  46]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 96,  76,  55],\n",
            "        [ 95,  74,  55],\n",
            "        [101,  79,  60],\n",
            "        ...,\n",
            "        [206, 188, 167],\n",
            "        [206, 189, 168],\n",
            "        [208, 190, 170]],\n",
            "\n",
            "       [[ 85,  64,  45],\n",
            "        [ 88,  66,  48],\n",
            "        [ 89,  67,  49],\n",
            "        ...,\n",
            "        [209, 190, 168],\n",
            "        [209, 190, 168],\n",
            "        [209, 189, 168]],\n",
            "\n",
            "       [[ 79,  59,  40],\n",
            "        [ 83,  61,  43],\n",
            "        [ 87,  66,  47],\n",
            "        ...,\n",
            "        [207, 191, 167],\n",
            "        [207, 191, 168],\n",
            "        [207, 190, 166]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road650.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7590529998869897, 'inference': 6.473289999803455, 'postprocess': 0.48447200015289127}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 86,  81,  56],\n",
            "        [ 88,  79,  58],\n",
            "        [ 90,  80,  59],\n",
            "        ...,\n",
            "        [ 79,  81,  70],\n",
            "        [ 85,  86,  76],\n",
            "        [ 88,  91,  80]],\n",
            "\n",
            "       [[ 88,  82,  57],\n",
            "        [ 88,  80,  59],\n",
            "        [ 85,  76,  55],\n",
            "        ...,\n",
            "        [ 78,  79,  69],\n",
            "        [ 89,  92,  81],\n",
            "        [100, 105,  94]],\n",
            "\n",
            "       [[ 88,  81,  59],\n",
            "        [ 89,  81,  60],\n",
            "        [ 85,  77,  56],\n",
            "        ...,\n",
            "        [ 80,  84,  73],\n",
            "        [ 86,  90,  79],\n",
            "        [ 94,  99,  88]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[149, 169, 171],\n",
            "        [162, 180, 183],\n",
            "        [162, 182, 185],\n",
            "        ...,\n",
            "        [155, 176, 183],\n",
            "        [163, 185, 192],\n",
            "        [161, 183, 189]],\n",
            "\n",
            "       [[163, 181, 184],\n",
            "        [167, 184, 187],\n",
            "        [172, 190, 194],\n",
            "        ...,\n",
            "        [175, 197, 204],\n",
            "        [161, 183, 189],\n",
            "        [162, 184, 190]],\n",
            "\n",
            "       [[170, 188, 189],\n",
            "        [167, 183, 187],\n",
            "        [172, 191, 193],\n",
            "        ...,\n",
            "        [174, 199, 203],\n",
            "        [173, 198, 202],\n",
            "        [152, 178, 182]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road656.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.8466669998815632, 'inference': 6.813843999907476, 'postprocess': 0.7147310000163998}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255]],\n",
            "\n",
            "       [[255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255]],\n",
            "\n",
            "       [[255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        ...,\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255],\n",
            "        [255, 255, 255]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[113, 108, 105],\n",
            "        [115, 111, 108],\n",
            "        [117, 112, 109],\n",
            "        ...,\n",
            "        [126, 120, 122],\n",
            "        [132, 125, 128],\n",
            "        [133, 126, 128]],\n",
            "\n",
            "       [[113, 109, 106],\n",
            "        [116, 111, 109],\n",
            "        [117, 112, 110],\n",
            "        ...,\n",
            "        [120, 109, 113],\n",
            "        [121, 110, 115],\n",
            "        [121, 110, 113]],\n",
            "\n",
            "       [[118, 113, 110],\n",
            "        [119, 115, 112],\n",
            "        [121, 116, 113],\n",
            "        ...,\n",
            "        [120, 106, 111],\n",
            "        [118, 103, 109],\n",
            "        [118, 103, 109]]], dtype=uint8)\n",
            "orig_shape: (301, 400)\n",
            "path: '/content/yolo_datasets/images/val/road66.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.3893719999250607, 'inference': 39.80712699990363, 'postprocess': 0.4816969999410503}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 72,  74,  62],\n",
            "        [ 76,  74,  66],\n",
            "        [ 81,  78,  70],\n",
            "        ...,\n",
            "        [ 71,  80,  83],\n",
            "        [152, 166, 174],\n",
            "        [105, 121, 129]],\n",
            "\n",
            "       [[ 72,  73,  62],\n",
            "        [ 77,  75,  67],\n",
            "        [ 77,  75,  66],\n",
            "        ...,\n",
            "        [111, 124, 128],\n",
            "        [129, 145, 152],\n",
            "        [ 83,  96, 104]],\n",
            "\n",
            "       [[ 73,  71,  63],\n",
            "        [ 79,  77,  68],\n",
            "        [ 76,  73,  64],\n",
            "        ...,\n",
            "        [133, 144, 147],\n",
            "        [102, 113, 118],\n",
            "        [ 93, 100, 104]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[176, 209, 225],\n",
            "        [178, 210, 227],\n",
            "        [180, 212, 229],\n",
            "        ...,\n",
            "        [172, 209, 233],\n",
            "        [171, 209, 233],\n",
            "        [159, 196, 220]],\n",
            "\n",
            "       [[176, 208, 223],\n",
            "        [177, 208, 224],\n",
            "        [175, 208, 224],\n",
            "        ...,\n",
            "        [163, 198, 221],\n",
            "        [168, 202, 225],\n",
            "        [171, 205, 228]],\n",
            "\n",
            "       [[176, 208, 223],\n",
            "        [173, 205, 220],\n",
            "        [175, 208, 224],\n",
            "        ...,\n",
            "        [147, 186, 204],\n",
            "        [160, 198, 216],\n",
            "        [169, 208, 226]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road662.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6037949999372358, 'inference': 6.490316000054008, 'postprocess': 0.4682599999341619}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 77,  83,  77],\n",
            "        [ 83,  86,  84],\n",
            "        [ 88,  91,  89],\n",
            "        ...,\n",
            "        [148, 156, 158],\n",
            "        [138, 143, 143],\n",
            "        [135, 140, 139]],\n",
            "\n",
            "       [[ 80,  85,  81],\n",
            "        [ 86,  89,  87],\n",
            "        [ 85,  88,  86],\n",
            "        ...,\n",
            "        [119, 125, 125],\n",
            "        [107, 112, 111],\n",
            "        [117, 121, 120]],\n",
            "\n",
            "       [[ 79,  83,  80],\n",
            "        [ 92,  95,  93],\n",
            "        [ 86,  89,  87],\n",
            "        ...,\n",
            "        [107, 112, 111],\n",
            "        [118, 123, 123],\n",
            "        [134, 138, 139]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[130, 153, 161],\n",
            "        [107, 127, 135],\n",
            "        [122, 138, 148],\n",
            "        ...,\n",
            "        [148, 129, 116],\n",
            "        [146, 129, 118],\n",
            "        [145, 128, 119]],\n",
            "\n",
            "       [[181, 205, 213],\n",
            "        [117, 138, 147],\n",
            "        [108, 124, 134],\n",
            "        ...,\n",
            "        [148, 129, 116],\n",
            "        [144, 127, 115],\n",
            "        [144, 127, 118]],\n",
            "\n",
            "       [[159, 184, 192],\n",
            "        [114, 136, 144],\n",
            "        [107, 122, 131],\n",
            "        ...,\n",
            "        [147, 131, 117],\n",
            "        [143, 127, 114],\n",
            "        [140, 124, 112]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road666.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.5886450000834884, 'inference': 5.8967990000837744, 'postprocess': 0.4598980001446762}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[160, 177, 173],\n",
            "        [204, 212, 204],\n",
            "        [180, 172, 167],\n",
            "        ...,\n",
            "        [ 91,  71,  59],\n",
            "        [ 91,  71,  59],\n",
            "        [ 89,  69,  57]],\n",
            "\n",
            "       [[133, 165, 168],\n",
            "        [154, 179, 183],\n",
            "        [198, 207, 206],\n",
            "        ...,\n",
            "        [ 95,  77,  65],\n",
            "        [ 97,  79,  67],\n",
            "        [ 90,  71,  59]],\n",
            "\n",
            "       [[147, 184, 186],\n",
            "        [135, 167, 174],\n",
            "        [147, 170, 176],\n",
            "        ...,\n",
            "        [ 98,  80,  68],\n",
            "        [103,  85,  74],\n",
            "        [ 93,  76,  64]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[167, 139, 117],\n",
            "        [169, 140, 120],\n",
            "        [169, 140, 119],\n",
            "        ...,\n",
            "        [154, 128, 109],\n",
            "        [153, 126, 107],\n",
            "        [154, 127, 108]],\n",
            "\n",
            "       [[167, 139, 118],\n",
            "        [169, 140, 119],\n",
            "        [169, 140, 119],\n",
            "        ...,\n",
            "        [156, 130, 111],\n",
            "        [155, 129, 110],\n",
            "        [157, 131, 112]],\n",
            "\n",
            "       [[169, 142, 119],\n",
            "        [169, 141, 119],\n",
            "        [168, 140, 118],\n",
            "        ...,\n",
            "        [155, 131, 111],\n",
            "        [154, 131, 110],\n",
            "        [154, 131, 110]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road667.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7665400000623777, 'inference': 5.88678499980233, 'postprocess': 0.4699289997915912}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[ 93, 107, 101],\n",
            "        [ 81,  92,  89],\n",
            "        [102, 112, 112],\n",
            "        ...,\n",
            "        [ 54,  47,  38],\n",
            "        [ 54,  47,  39],\n",
            "        [ 54,  47,  39]],\n",
            "\n",
            "       [[131, 148, 142],\n",
            "        [ 98, 112, 109],\n",
            "        [100, 109, 111],\n",
            "        ...,\n",
            "        [ 54,  47,  38],\n",
            "        [ 54,  47,  39],\n",
            "        [ 55,  47,  40]],\n",
            "\n",
            "       [[135, 152, 146],\n",
            "        [112, 127, 124],\n",
            "        [ 64,  70,  72],\n",
            "        ...,\n",
            "        [ 56,  48,  40],\n",
            "        [ 55,  47,  40],\n",
            "        [ 54,  46,  38]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[118, 107,  87],\n",
            "        [119, 107,  88],\n",
            "        [119, 107,  88],\n",
            "        ...,\n",
            "        [133, 125, 110],\n",
            "        [141, 134, 119],\n",
            "        [140, 133, 118]],\n",
            "\n",
            "       [[119, 107,  90],\n",
            "        [119, 107,  89],\n",
            "        [119, 107,  88],\n",
            "        ...,\n",
            "        [122, 114, 101],\n",
            "        [127, 119, 106],\n",
            "        [135, 127, 114]],\n",
            "\n",
            "       [[118, 108,  89],\n",
            "        [117, 107,  87],\n",
            "        [115, 105,  85],\n",
            "        ...,\n",
            "        [118, 113,  99],\n",
            "        [112, 108,  94],\n",
            "        [103,  98,  85]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road678.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.710694999905172, 'inference': 9.424734000049284, 'postprocess': 0.9046069999385509}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[208, 207, 163],\n",
            "        [211, 206, 165],\n",
            "        [211, 207, 165],\n",
            "        ...,\n",
            "        [213, 207, 163],\n",
            "        [213, 207, 163],\n",
            "        [214, 208, 164]],\n",
            "\n",
            "       [[208, 207, 164],\n",
            "        [211, 206, 166],\n",
            "        [211, 206, 166],\n",
            "        ...,\n",
            "        [214, 208, 164],\n",
            "        [213, 207, 163],\n",
            "        [213, 207, 163]],\n",
            "\n",
            "       [[210, 207, 165],\n",
            "        [211, 206, 166],\n",
            "        [211, 206, 166],\n",
            "        ...,\n",
            "        [214, 208, 164],\n",
            "        [213, 207, 163],\n",
            "        [213, 207, 163]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[111, 119, 105],\n",
            "        [113, 118, 105],\n",
            "        [115, 119, 106],\n",
            "        ...,\n",
            "        [ 84,  85,  68],\n",
            "        [ 84,  85,  68],\n",
            "        [ 84,  85,  68]],\n",
            "\n",
            "       [[112, 120, 106],\n",
            "        [113, 120, 107],\n",
            "        [116, 122, 109],\n",
            "        ...,\n",
            "        [ 81,  83,  66],\n",
            "        [ 83,  84,  67],\n",
            "        [ 83,  84,  67]],\n",
            "\n",
            "       [[112, 122, 106],\n",
            "        [113, 121, 107],\n",
            "        [115, 123, 109],\n",
            "        ...,\n",
            "        [ 79,  83,  64],\n",
            "        [ 81,  85,  66],\n",
            "        [ 80,  84,  65]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road687.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.807094000014331, 'inference': 5.898476000083974, 'postprocess': 0.48514300010538136}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[230, 199, 160],\n",
            "        [229, 198, 159],\n",
            "        [229, 198, 159],\n",
            "        ...,\n",
            "        [254, 247, 231],\n",
            "        [254, 247, 231],\n",
            "        [254, 247, 231]],\n",
            "\n",
            "       [[230, 199, 160],\n",
            "        [230, 199, 159],\n",
            "        [230, 199, 159],\n",
            "        ...,\n",
            "        [254, 247, 231],\n",
            "        [254, 247, 231],\n",
            "        [254, 247, 231]],\n",
            "\n",
            "       [[231, 200, 160],\n",
            "        [230, 199, 160],\n",
            "        [230, 199, 160],\n",
            "        ...,\n",
            "        [254, 247, 231],\n",
            "        [254, 247, 231],\n",
            "        [254, 247, 231]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[217, 202, 166],\n",
            "        [218, 203, 166],\n",
            "        [218, 203, 167],\n",
            "        ...,\n",
            "        [243, 236, 217],\n",
            "        [243, 236, 217],\n",
            "        [243, 236, 217]],\n",
            "\n",
            "       [[217, 202, 166],\n",
            "        [218, 203, 167],\n",
            "        [218, 203, 167],\n",
            "        ...,\n",
            "        [243, 236, 217],\n",
            "        [243, 236, 217],\n",
            "        [243, 236, 217]],\n",
            "\n",
            "       [[217, 202, 166],\n",
            "        [218, 203, 167],\n",
            "        [218, 203, 167],\n",
            "        ...,\n",
            "        [243, 236, 217],\n",
            "        [243, 236, 217],\n",
            "        [243, 236, 217]]], dtype=uint8)\n",
            "orig_shape: (301, 400)\n",
            "path: '/content/yolo_datasets/images/val/road69.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.3870770000939956, 'inference': 6.498525000097288, 'postprocess': 0.46121899981699244}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[194, 201, 164],\n",
            "        [198, 201, 168],\n",
            "        [197, 200, 167],\n",
            "        ...,\n",
            "        [203, 199, 163],\n",
            "        [203, 199, 163],\n",
            "        [202, 198, 162]],\n",
            "\n",
            "       [[193, 199, 163],\n",
            "        [195, 198, 166],\n",
            "        [196, 199, 166],\n",
            "        ...,\n",
            "        [203, 199, 163],\n",
            "        [203, 199, 163],\n",
            "        [203, 200, 164]],\n",
            "\n",
            "       [[194, 199, 164],\n",
            "        [196, 199, 167],\n",
            "        [196, 199, 167],\n",
            "        ...,\n",
            "        [204, 200, 164],\n",
            "        [203, 200, 164],\n",
            "        [202, 200, 164]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[126, 136, 119],\n",
            "        [124, 133, 117],\n",
            "        [122, 132, 115],\n",
            "        ...,\n",
            "        [131, 154, 151],\n",
            "        [135, 158, 155],\n",
            "        [128, 151, 148]],\n",
            "\n",
            "       [[125, 138, 121],\n",
            "        [123, 133, 117],\n",
            "        [120, 131, 114],\n",
            "        ...,\n",
            "        [135, 160, 156],\n",
            "        [135, 160, 157],\n",
            "        [132, 156, 153]],\n",
            "\n",
            "       [[122, 135, 118],\n",
            "        [123, 135, 118],\n",
            "        [124, 136, 119],\n",
            "        ...,\n",
            "        [150, 180, 173],\n",
            "        [145, 176, 169],\n",
            "        [137, 168, 161]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road696.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.693814999953247, 'inference': 6.528272999958062, 'postprocess': 0.4729439999664464}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[201, 220, 205],\n",
            "        [200, 217, 204],\n",
            "        [197, 213, 199],\n",
            "        ...,\n",
            "        [216, 229, 213],\n",
            "        [214, 225, 209],\n",
            "        [218, 225, 210]],\n",
            "\n",
            "       [[199, 217, 203],\n",
            "        [198, 214, 202],\n",
            "        [197, 213, 199],\n",
            "        ...,\n",
            "        [213, 226, 210],\n",
            "        [213, 224, 208],\n",
            "        [214, 222, 205]],\n",
            "\n",
            "       [[195, 214, 199],\n",
            "        [198, 214, 202],\n",
            "        [196, 213, 199],\n",
            "        ...,\n",
            "        [213, 224, 208],\n",
            "        [208, 217, 200],\n",
            "        [206, 214, 197]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 98, 110, 108],\n",
            "        [100, 112, 110],\n",
            "        [112, 124, 123],\n",
            "        ...,\n",
            "        [ 82,  93,  87],\n",
            "        [127, 141, 134],\n",
            "        [144, 162, 152]],\n",
            "\n",
            "       [[105, 122, 116],\n",
            "        [105, 119, 116],\n",
            "        [106, 120, 118],\n",
            "        ...,\n",
            "        [101, 116, 108],\n",
            "        [141, 157, 149],\n",
            "        [145, 164, 153]],\n",
            "\n",
            "       [[110, 127, 121],\n",
            "        [108, 124, 119],\n",
            "        [102, 119, 114],\n",
            "        ...,\n",
            "        [116, 137, 124],\n",
            "        [133, 155, 142],\n",
            "        [139, 164, 149]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road700.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.589901999977883, 'inference': 5.895712999972602, 'postprocess': 0.6642870000632684}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[209, 242, 226],\n",
            "        [208, 237, 225],\n",
            "        [204, 232, 220],\n",
            "        ...,\n",
            "        [ 78,  82,  71],\n",
            "        [ 84,  90,  76],\n",
            "        [168, 179, 160]],\n",
            "\n",
            "       [[191, 218, 204],\n",
            "        [196, 220, 208],\n",
            "        [198, 223, 211],\n",
            "        ...,\n",
            "        [ 79,  84,  72],\n",
            "        [ 82,  88,  75],\n",
            "        [175, 186, 167]],\n",
            "\n",
            "       [[181, 200, 187],\n",
            "        [186, 204, 192],\n",
            "        [190, 210, 198],\n",
            "        ...,\n",
            "        [ 77,  81,  69],\n",
            "        [ 76,  81,  68],\n",
            "        [178, 189, 170]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[131, 143, 125],\n",
            "        [131, 142, 125],\n",
            "        [130, 141, 124],\n",
            "        ...,\n",
            "        [112, 124, 112],\n",
            "        [119, 131, 119],\n",
            "        [120, 132, 120]],\n",
            "\n",
            "       [[127, 140, 123],\n",
            "        [129, 140, 123],\n",
            "        [130, 141, 124],\n",
            "        ...,\n",
            "        [115, 127, 115],\n",
            "        [115, 127, 115],\n",
            "        [121, 133, 121]],\n",
            "\n",
            "       [[128, 142, 124],\n",
            "        [130, 143, 125],\n",
            "        [129, 142, 124],\n",
            "        ...,\n",
            "        [115, 130, 116],\n",
            "        [111, 126, 112],\n",
            "        [117, 131, 118]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road710.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.596376000179589, 'inference': 5.894683999940753, 'postprocess': 0.5137010000453301}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[203, 214, 184],\n",
            "        [207, 215, 188],\n",
            "        [212, 223, 203],\n",
            "        ...,\n",
            "        [191, 182, 143],\n",
            "        [192, 183, 144],\n",
            "        [194, 185, 147]],\n",
            "\n",
            "       [[205, 224, 205],\n",
            "        [215, 231, 215],\n",
            "        [224, 243, 231],\n",
            "        ...,\n",
            "        [190, 179, 138],\n",
            "        [191, 180, 139],\n",
            "        [196, 185, 144]],\n",
            "\n",
            "       [[221, 246, 235],\n",
            "        [227, 250, 241],\n",
            "        [228, 252, 245],\n",
            "        ...,\n",
            "        [192, 179, 139],\n",
            "        [193, 180, 140],\n",
            "        [194, 181, 141]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[138, 146, 125],\n",
            "        [138, 144, 125],\n",
            "        [135, 141, 122],\n",
            "        ...,\n",
            "        [160, 185, 180],\n",
            "        [164, 189, 183],\n",
            "        [164, 189, 183]],\n",
            "\n",
            "       [[135, 142, 122],\n",
            "        [135, 141, 122],\n",
            "        [135, 141, 122],\n",
            "        ...,\n",
            "        [169, 193, 188],\n",
            "        [167, 191, 186],\n",
            "        [166, 190, 185]],\n",
            "\n",
            "       [[129, 137, 116],\n",
            "        [119, 127, 106],\n",
            "        [132, 140, 119],\n",
            "        ...,\n",
            "        [159, 186, 178],\n",
            "        [165, 192, 184],\n",
            "        [166, 193, 185]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road716.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.722853000046598, 'inference': 5.907771000011053, 'postprocess': 0.471744999913426}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[224, 213, 148],\n",
            "        [226, 213, 150],\n",
            "        [226, 213, 150],\n",
            "        ...,\n",
            "        [231, 217, 157],\n",
            "        [232, 218, 158],\n",
            "        [232, 219, 158]],\n",
            "\n",
            "       [[225, 214, 149],\n",
            "        [227, 213, 151],\n",
            "        [228, 213, 151],\n",
            "        ...,\n",
            "        [231, 217, 157],\n",
            "        [231, 217, 157],\n",
            "        [230, 216, 156]],\n",
            "\n",
            "       [[227, 212, 150],\n",
            "        [228, 212, 150],\n",
            "        [228, 213, 151],\n",
            "        ...,\n",
            "        [231, 217, 157],\n",
            "        [230, 217, 156],\n",
            "        [230, 217, 156]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[136, 152, 146],\n",
            "        [136, 152, 145],\n",
            "        [137, 153, 146],\n",
            "        ...,\n",
            "        [ 88,  86,  71],\n",
            "        [ 86,  85,  68],\n",
            "        [ 81,  81,  65]],\n",
            "\n",
            "       [[135, 152, 145],\n",
            "        [134, 150, 143],\n",
            "        [137, 153, 146],\n",
            "        ...,\n",
            "        [ 92,  90,  74],\n",
            "        [ 86,  86,  70],\n",
            "        [ 90,  90,  72]],\n",
            "\n",
            "       [[130, 148, 140],\n",
            "        [130, 146, 139],\n",
            "        [130, 147, 139],\n",
            "        ...,\n",
            "        [ 94,  95,  75],\n",
            "        [ 87,  89,  69],\n",
            "        [ 93,  95,  73]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road727.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.684460999967996, 'inference': 5.8929530000568775, 'postprocess': 0.47000599988678005}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[233, 222, 159],\n",
            "        [235, 220, 161],\n",
            "        [233, 218, 159],\n",
            "        ...,\n",
            "        [231, 218, 160],\n",
            "        [232, 219, 161],\n",
            "        [232, 219, 161]],\n",
            "\n",
            "       [[233, 221, 159],\n",
            "        [235, 221, 161],\n",
            "        [234, 220, 161],\n",
            "        ...,\n",
            "        [232, 219, 161],\n",
            "        [231, 218, 160],\n",
            "        [232, 219, 161]],\n",
            "\n",
            "       [[234, 222, 163],\n",
            "        [232, 219, 161],\n",
            "        [232, 219, 161],\n",
            "        ...,\n",
            "        [231, 219, 160],\n",
            "        [231, 219, 160],\n",
            "        [235, 222, 164]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[133, 146, 135],\n",
            "        [134, 145, 135],\n",
            "        [136, 147, 137],\n",
            "        ...,\n",
            "        [109, 102,  82],\n",
            "        [102,  95,  74],\n",
            "        [101,  94,  74]],\n",
            "\n",
            "       [[132, 144, 133],\n",
            "        [132, 143, 133],\n",
            "        [133, 143, 134],\n",
            "        ...,\n",
            "        [113, 107,  86],\n",
            "        [110, 103,  82],\n",
            "        [105,  98,  78]],\n",
            "\n",
            "       [[130, 144, 132],\n",
            "        [131, 143, 133],\n",
            "        [132, 145, 134],\n",
            "        ...,\n",
            "        [112, 109,  84],\n",
            "        [107, 104,  79],\n",
            "        [103,  99,  76]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road728.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7027479998432682, 'inference': 5.898505999994086, 'postprocess': 0.46486299993375724}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[  4,   5,  19],\n",
            "        [  4,   5,  19],\n",
            "        [  4,   5,  19],\n",
            "        ...,\n",
            "        [ 16,  35,  40],\n",
            "        [ 10,  28,  33],\n",
            "        [  7,  26,  30]],\n",
            "\n",
            "       [[  4,   5,  19],\n",
            "        [  4,   5,  19],\n",
            "        [  4,   5,  19],\n",
            "        ...,\n",
            "        [ 16,  35,  40],\n",
            "        [ 10,  29,  33],\n",
            "        [  7,  26,  30]],\n",
            "\n",
            "       [[  4,   5,  19],\n",
            "        [  5,   6,  20],\n",
            "        [  5,   6,  20],\n",
            "        ...,\n",
            "        [ 17,  36,  41],\n",
            "        [ 13,  31,  36],\n",
            "        [ 12,  29,  33]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 45,  86, 106],\n",
            "        [ 48,  89, 109],\n",
            "        [ 50,  91, 111],\n",
            "        ...,\n",
            "        [ 60,  90, 115],\n",
            "        [ 58,  89, 114],\n",
            "        [ 56,  87, 113]],\n",
            "\n",
            "       [[ 45,  85, 106],\n",
            "        [ 48,  89, 109],\n",
            "        [ 49,  90, 110],\n",
            "        ...,\n",
            "        [ 59,  89, 114],\n",
            "        [ 56,  87, 113],\n",
            "        [ 55,  86, 112]],\n",
            "\n",
            "       [[ 46,  87, 108],\n",
            "        [ 48,  89, 109],\n",
            "        [ 47,  88, 108],\n",
            "        ...,\n",
            "        [ 57,  86, 112],\n",
            "        [ 54,  86, 111],\n",
            "        [ 53,  85, 110]]], dtype=uint8)\n",
            "orig_shape: (269, 400)\n",
            "path: '/content/yolo_datasets/images/val/road73.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 2.0827900000313093, 'inference': 6.380157999956282, 'postprocess': 0.4441190001216455}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[167, 156, 118],\n",
            "        [169, 155, 119],\n",
            "        [169, 155, 118],\n",
            "        ...,\n",
            "        [188, 174, 126],\n",
            "        [189, 175, 127],\n",
            "        [190, 176, 128]],\n",
            "\n",
            "       [[166, 156, 116],\n",
            "        [168, 154, 116],\n",
            "        [168, 154, 117],\n",
            "        ...,\n",
            "        [194, 180, 131],\n",
            "        [196, 183, 134],\n",
            "        [194, 181, 132]],\n",
            "\n",
            "       [[168, 154, 116],\n",
            "        [169, 154, 116],\n",
            "        [168, 154, 116],\n",
            "        ...,\n",
            "        [197, 185, 135],\n",
            "        [200, 187, 138],\n",
            "        [195, 182, 133]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[124, 136, 132],\n",
            "        [127, 138, 135],\n",
            "        [130, 142, 137],\n",
            "        ...,\n",
            "        [116, 137, 134],\n",
            "        [114, 135, 132],\n",
            "        [123, 144, 141]],\n",
            "\n",
            "       [[133, 145, 141],\n",
            "        [129, 140, 135],\n",
            "        [124, 136, 130],\n",
            "        ...,\n",
            "        [114, 135, 132],\n",
            "        [115, 136, 133],\n",
            "        [122, 143, 141]],\n",
            "\n",
            "       [[130, 143, 138],\n",
            "        [121, 134, 128],\n",
            "        [116, 129, 122],\n",
            "        ...,\n",
            "        [113, 137, 131],\n",
            "        [116, 140, 134],\n",
            "        [115, 139, 133]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road748.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6609879999123223, 'inference': 6.492373000128282, 'postprocess': 0.46180399999684596}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[205, 197, 144],\n",
            "        [207, 195, 145],\n",
            "        [207, 195, 145],\n",
            "        ...,\n",
            "        [214, 202, 153],\n",
            "        [214, 202, 152],\n",
            "        [213, 201, 151]],\n",
            "\n",
            "       [[204, 196, 144],\n",
            "        [207, 195, 145],\n",
            "        [206, 195, 144],\n",
            "        ...,\n",
            "        [212, 201, 154],\n",
            "        [212, 200, 153],\n",
            "        [215, 203, 156]],\n",
            "\n",
            "       [[204, 195, 146],\n",
            "        [205, 194, 145],\n",
            "        [207, 195, 145],\n",
            "        ...,\n",
            "        [202, 191, 148],\n",
            "        [201, 189, 146],\n",
            "        [202, 190, 147]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[128, 150, 148],\n",
            "        [129, 151, 148],\n",
            "        [129, 150, 148],\n",
            "        ...,\n",
            "        [119, 141, 140],\n",
            "        [118, 140, 139],\n",
            "        [119, 141, 140]],\n",
            "\n",
            "       [[122, 144, 140],\n",
            "        [124, 145, 142],\n",
            "        [123, 143, 142],\n",
            "        ...,\n",
            "        [122, 144, 143],\n",
            "        [120, 143, 141],\n",
            "        [117, 140, 138]],\n",
            "\n",
            "       [[121, 144, 139],\n",
            "        [113, 134, 131],\n",
            "        [118, 139, 137],\n",
            "        ...,\n",
            "        [124, 148, 145],\n",
            "        [123, 148, 144],\n",
            "        [120, 144, 141]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road752.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.5350179999131797, 'inference': 5.917004000139059, 'postprocess': 0.48736999997345265}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[173, 157, 114],\n",
            "        [175, 157, 116],\n",
            "        [175, 157, 116],\n",
            "        ...,\n",
            "        [197, 186, 148],\n",
            "        [197, 184, 147],\n",
            "        [200, 187, 148]],\n",
            "\n",
            "       [[174, 157, 114],\n",
            "        [175, 157, 116],\n",
            "        [175, 157, 115],\n",
            "        ...,\n",
            "        [191, 181, 144],\n",
            "        [195, 184, 146],\n",
            "        [199, 187, 149]],\n",
            "\n",
            "       [[174, 156, 115],\n",
            "        [174, 157, 116],\n",
            "        [174, 156, 115],\n",
            "        ...,\n",
            "        [192, 183, 147],\n",
            "        [193, 183, 145],\n",
            "        [195, 186, 147]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[120, 123, 110],\n",
            "        [122, 124, 112],\n",
            "        [121, 123, 111],\n",
            "        ...,\n",
            "        [133, 133, 119],\n",
            "        [132, 132, 118],\n",
            "        [125, 125, 111]],\n",
            "\n",
            "       [[121, 124, 111],\n",
            "        [120, 122, 110],\n",
            "        [118, 120, 108],\n",
            "        ...,\n",
            "        [132, 132, 118],\n",
            "        [132, 132, 118],\n",
            "        [123, 123, 109]],\n",
            "\n",
            "       [[118, 122, 108],\n",
            "        [119, 122, 109],\n",
            "        [116, 119, 105],\n",
            "        ...,\n",
            "        [130, 133, 117],\n",
            "        [130, 132, 116],\n",
            "        [119, 122, 106]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road755.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.5791759999501664, 'inference': 5.902138999999806, 'postprocess': 0.47259799998755625}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[221, 205, 138],\n",
            "        [224, 204, 141],\n",
            "        [223, 204, 140],\n",
            "        ...,\n",
            "        [224, 203, 140],\n",
            "        [224, 203, 140],\n",
            "        [224, 204, 140]],\n",
            "\n",
            "       [[221, 205, 139],\n",
            "        [223, 203, 140],\n",
            "        [224, 204, 141],\n",
            "        ...,\n",
            "        [224, 203, 140],\n",
            "        [225, 204, 141],\n",
            "        [224, 204, 140]],\n",
            "\n",
            "       [[222, 204, 139],\n",
            "        [223, 203, 140],\n",
            "        [223, 203, 140],\n",
            "        ...,\n",
            "        [224, 203, 140],\n",
            "        [224, 204, 140],\n",
            "        [225, 204, 141]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 98,  86,  58],\n",
            "        [ 94,  82,  54],\n",
            "        [ 94,  83,  55],\n",
            "        ...,\n",
            "        [ 84,  74,  49],\n",
            "        [ 83,  73,  48],\n",
            "        [ 83,  73,  48]],\n",
            "\n",
            "       [[ 89,  79,  51],\n",
            "        [ 92,  82,  53],\n",
            "        [ 91,  80,  52],\n",
            "        ...,\n",
            "        [ 86,  77,  52],\n",
            "        [ 83,  73,  48],\n",
            "        [ 85,  75,  50]],\n",
            "\n",
            "       [[ 90,  81,  52],\n",
            "        [ 92,  83,  54],\n",
            "        [ 86,  77,  48],\n",
            "        ...,\n",
            "        [ 81,  74,  47],\n",
            "        [ 79,  71,  44],\n",
            "        [ 83,  75,  48]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road777.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7351089998101088, 'inference': 5.893787000104567, 'postprocess': 0.46524100002898194}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[231, 206, 137],\n",
            "        [234, 207, 140],\n",
            "        [234, 207, 140],\n",
            "        ...,\n",
            "        [228, 199, 136],\n",
            "        [228, 199, 136],\n",
            "        [228, 199, 136]],\n",
            "\n",
            "       [[232, 207, 138],\n",
            "        [233, 206, 139],\n",
            "        [234, 207, 140],\n",
            "        ...,\n",
            "        [227, 198, 135],\n",
            "        [228, 199, 136],\n",
            "        [228, 199, 136]],\n",
            "\n",
            "       [[232, 206, 139],\n",
            "        [233, 206, 139],\n",
            "        [234, 207, 139],\n",
            "        ...,\n",
            "        [228, 199, 136],\n",
            "        [228, 199, 136],\n",
            "        [227, 198, 135]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[129, 153, 150],\n",
            "        [118, 140, 139],\n",
            "        [126, 148, 146],\n",
            "        ...,\n",
            "        [118, 134, 133],\n",
            "        [119, 135, 134],\n",
            "        [118, 133, 133]],\n",
            "\n",
            "       [[101, 123, 119],\n",
            "        [ 98, 119, 117],\n",
            "        [ 99, 120, 118],\n",
            "        ...,\n",
            "        [113, 129, 128],\n",
            "        [112, 127, 127],\n",
            "        [115, 131, 130]],\n",
            "\n",
            "       [[ 95, 119, 114],\n",
            "        [106, 128, 124],\n",
            "        [ 94, 115, 113],\n",
            "        ...,\n",
            "        [111, 129, 127],\n",
            "        [106, 124, 122],\n",
            "        [114, 132, 129]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road781.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6907940000692179, 'inference': 5.915008999863858, 'postprocess': 0.47852000011516793}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[225, 214, 150],\n",
            "        [227, 213, 151],\n",
            "        [226, 213, 150],\n",
            "        ...,\n",
            "        [233, 216, 154],\n",
            "        [232, 216, 154],\n",
            "        [232, 216, 154]],\n",
            "\n",
            "       [[226, 214, 150],\n",
            "        [227, 213, 151],\n",
            "        [227, 213, 151],\n",
            "        ...,\n",
            "        [232, 216, 154],\n",
            "        [233, 217, 155],\n",
            "        [234, 216, 154]],\n",
            "\n",
            "       [[226, 214, 151],\n",
            "        [227, 213, 151],\n",
            "        [227, 213, 151],\n",
            "        ...,\n",
            "        [233, 217, 154],\n",
            "        [233, 217, 155],\n",
            "        [233, 216, 154]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[107,  84,  47],\n",
            "        [108,  84,  47],\n",
            "        [108,  84,  48],\n",
            "        ...,\n",
            "        [123, 116,  96],\n",
            "        [122, 116,  95],\n",
            "        [121, 115,  94]],\n",
            "\n",
            "       [[106,  83,  47],\n",
            "        [108,  83,  47],\n",
            "        [111,  84,  48],\n",
            "        ...,\n",
            "        [124, 117,  96],\n",
            "        [123, 116,  95],\n",
            "        [122, 115,  94]],\n",
            "\n",
            "       [[105,  83,  45],\n",
            "        [107,  83,  47],\n",
            "        [110,  85,  48],\n",
            "        ...,\n",
            "        [124, 119,  95],\n",
            "        [121, 117,  93],\n",
            "        [121, 117,  92]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road797.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.8202799999471608, 'inference': 5.889211000067007, 'postprocess': 0.4776450000463228}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[230, 197, 122],\n",
            "        [232, 195, 123],\n",
            "        [230, 194, 122],\n",
            "        ...,\n",
            "        [231, 196, 122],\n",
            "        [230, 195, 121],\n",
            "        [231, 196, 122]],\n",
            "\n",
            "       [[230, 197, 124],\n",
            "        [231, 195, 123],\n",
            "        [231, 195, 123],\n",
            "        ...,\n",
            "        [231, 196, 122],\n",
            "        [231, 196, 122],\n",
            "        [231, 196, 122]],\n",
            "\n",
            "       [[230, 197, 122],\n",
            "        [230, 194, 122],\n",
            "        [231, 194, 122],\n",
            "        ...,\n",
            "        [232, 197, 123],\n",
            "        [232, 197, 123],\n",
            "        [231, 196, 122]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[177, 165, 125],\n",
            "        [185, 172, 133],\n",
            "        [182, 169, 129],\n",
            "        ...,\n",
            "        [205, 210, 174],\n",
            "        [204, 210, 174],\n",
            "        [207, 213, 177]],\n",
            "\n",
            "       [[171, 158, 121],\n",
            "        [179, 165, 129],\n",
            "        [167, 153, 115],\n",
            "        ...,\n",
            "        [193, 197, 161],\n",
            "        [199, 205, 169],\n",
            "        [205, 211, 175]],\n",
            "\n",
            "       [[175, 163, 126],\n",
            "        [180, 167, 131],\n",
            "        [151, 138, 100],\n",
            "        ...,\n",
            "        [185, 192, 154],\n",
            "        [184, 193, 154],\n",
            "        [192, 201, 162]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road801.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7394980000062787, 'inference': 5.893882000009398, 'postprocess': 0.4934690000482078}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[173, 169, 135],\n",
            "        [176, 169, 138],\n",
            "        [176, 168, 137],\n",
            "        ...,\n",
            "        [193, 190, 161],\n",
            "        [193, 190, 161],\n",
            "        [192, 189, 160]],\n",
            "\n",
            "       [[178, 170, 134],\n",
            "        [179, 168, 136],\n",
            "        [178, 167, 135],\n",
            "        ...,\n",
            "        [190, 187, 158],\n",
            "        [190, 187, 158],\n",
            "        [190, 187, 158]],\n",
            "\n",
            "       [[178, 170, 134],\n",
            "        [179, 169, 135],\n",
            "        [177, 167, 133],\n",
            "        ...,\n",
            "        [192, 189, 160],\n",
            "        [191, 188, 159],\n",
            "        [192, 189, 160]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[133, 148, 141],\n",
            "        [133, 147, 142],\n",
            "        [134, 148, 144],\n",
            "        ...,\n",
            "        [102,  86,  57],\n",
            "        [103,  87,  58],\n",
            "        [102,  85,  56]],\n",
            "\n",
            "       [[128, 142, 138],\n",
            "        [131, 144, 141],\n",
            "        [131, 144, 141],\n",
            "        ...,\n",
            "        [104,  88,  60],\n",
            "        [105,  88,  60],\n",
            "        [103,  87,  59]],\n",
            "\n",
            "       [[131, 146, 140],\n",
            "        [130, 144, 140],\n",
            "        [128, 142, 138],\n",
            "        ...,\n",
            "        [103,  89,  60],\n",
            "        [102,  89,  58],\n",
            "        [ 97,  84,  54]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road808.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6844100000525941, 'inference': 5.925703999992038, 'postprocess': 0.5601519999345328}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[203, 200, 157],\n",
            "        [207, 200, 160],\n",
            "        [216, 207, 168],\n",
            "        ...,\n",
            "        [212, 204, 166],\n",
            "        [206, 198, 160],\n",
            "        [206, 198, 160]],\n",
            "\n",
            "       [[205, 201, 161],\n",
            "        [207, 200, 162],\n",
            "        [210, 202, 164],\n",
            "        ...,\n",
            "        [210, 202, 164],\n",
            "        [208, 200, 162],\n",
            "        [208, 200, 162]],\n",
            "\n",
            "       [[205, 200, 163],\n",
            "        [206, 200, 164],\n",
            "        [209, 201, 166],\n",
            "        ...,\n",
            "        [209, 201, 163],\n",
            "        [208, 200, 162],\n",
            "        [205, 197, 159]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[124, 139, 132],\n",
            "        [120, 134, 128],\n",
            "        [121, 135, 129],\n",
            "        ...,\n",
            "        [ 91, 123, 131],\n",
            "        [ 85, 117, 125],\n",
            "        [ 91, 122, 130]],\n",
            "\n",
            "       [[127, 142, 135],\n",
            "        [119, 133, 127],\n",
            "        [119, 133, 127],\n",
            "        ...,\n",
            "        [ 85, 116, 123],\n",
            "        [ 89, 120, 126],\n",
            "        [ 93, 123, 129]],\n",
            "\n",
            "       [[126, 142, 134],\n",
            "        [126, 141, 133],\n",
            "        [122, 137, 129],\n",
            "        ...,\n",
            "        [ 86, 121, 124],\n",
            "        [ 94, 129, 131],\n",
            "        [ 91, 128, 131]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road809.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7455429999699845, 'inference': 5.930046999992555, 'postprocess': 0.454032999869014}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[223, 204, 136],\n",
            "        [225, 202, 138],\n",
            "        [223, 202, 138],\n",
            "        ...,\n",
            "        [224, 201, 137],\n",
            "        [224, 201, 137],\n",
            "        [224, 201, 137]],\n",
            "\n",
            "       [[223, 204, 136],\n",
            "        [224, 201, 138],\n",
            "        [223, 202, 138],\n",
            "        ...,\n",
            "        [224, 201, 137],\n",
            "        [224, 201, 137],\n",
            "        [224, 201, 137]],\n",
            "\n",
            "       [[224, 203, 136],\n",
            "        [224, 201, 137],\n",
            "        [222, 201, 137],\n",
            "        ...,\n",
            "        [225, 202, 138],\n",
            "        [224, 201, 137],\n",
            "        [224, 201, 137]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[110, 151, 163],\n",
            "        [107, 146, 159],\n",
            "        [108, 146, 159],\n",
            "        ...,\n",
            "        [111, 148, 161],\n",
            "        [106, 144, 158],\n",
            "        [111, 150, 163]],\n",
            "\n",
            "       [[118, 158, 170],\n",
            "        [119, 158, 172],\n",
            "        [121, 159, 173],\n",
            "        ...,\n",
            "        [115, 154, 167],\n",
            "        [112, 151, 165],\n",
            "        [117, 156, 170]],\n",
            "\n",
            "       [[104, 145, 156],\n",
            "        [111, 152, 163],\n",
            "        [121, 162, 174],\n",
            "        ...,\n",
            "        [117, 161, 170],\n",
            "        [117, 161, 170],\n",
            "        [119, 162, 171]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road811.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.728406999973231, 'inference': 5.8912749998398795, 'postprocess': 0.46712899984413525}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[225, 181, 110],\n",
            "        [227, 180, 112],\n",
            "        [227, 180, 109],\n",
            "        ...,\n",
            "        [220, 175, 107],\n",
            "        [221, 176, 108],\n",
            "        [221, 176, 108]],\n",
            "\n",
            "       [[226, 182, 111],\n",
            "        [228, 181, 113],\n",
            "        [227, 180, 109],\n",
            "        ...,\n",
            "        [221, 176, 108],\n",
            "        [221, 176, 108],\n",
            "        [221, 176, 108]],\n",
            "\n",
            "       [[226, 180, 111],\n",
            "        [227, 180, 112],\n",
            "        [227, 180, 110],\n",
            "        ...,\n",
            "        [221, 175, 109],\n",
            "        [223, 176, 108],\n",
            "        [223, 176, 108]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[124, 134, 125],\n",
            "        [126, 134, 127],\n",
            "        [125, 133, 126],\n",
            "        ...,\n",
            "        [115, 135, 138],\n",
            "        [115, 134, 138],\n",
            "        [115, 133, 137]],\n",
            "\n",
            "       [[124, 134, 125],\n",
            "        [124, 132, 125],\n",
            "        [124, 132, 125],\n",
            "        ...,\n",
            "        [117, 136, 136],\n",
            "        [114, 132, 133],\n",
            "        [115, 133, 133]],\n",
            "\n",
            "       [[121, 132, 122],\n",
            "        [122, 132, 123],\n",
            "        [123, 133, 124],\n",
            "        ...,\n",
            "        [117, 137, 134],\n",
            "        [114, 133, 130],\n",
            "        [113, 131, 128]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road820.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7424189998109796, 'inference': 5.932980000125099, 'postprocess': 0.4646150000553462}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[178, 132,  71],\n",
            "        [179, 130,  74],\n",
            "        [179, 130,  73],\n",
            "        ...,\n",
            "        [179, 142, 100],\n",
            "        [180, 142, 100],\n",
            "        [177, 141,  98]],\n",
            "\n",
            "       [[178, 132,  71],\n",
            "        [180, 131,  74],\n",
            "        [180, 131,  75],\n",
            "        ...,\n",
            "        [180, 144, 101],\n",
            "        [181, 143, 101],\n",
            "        [180, 143, 100]],\n",
            "\n",
            "       [[179, 132,  73],\n",
            "        [180, 130,  73],\n",
            "        [179, 130,  74],\n",
            "        ...,\n",
            "        [179, 145, 102],\n",
            "        [179, 144, 102],\n",
            "        [179, 144, 101]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[223, 190, 119],\n",
            "        [224, 190, 119],\n",
            "        [223, 190, 119],\n",
            "        ...,\n",
            "        [221, 186, 118],\n",
            "        [222, 187, 119],\n",
            "        [222, 187, 119]],\n",
            "\n",
            "       [[224, 191, 120],\n",
            "        [224, 191, 120],\n",
            "        [224, 190, 119],\n",
            "        ...,\n",
            "        [221, 186, 118],\n",
            "        [221, 186, 118],\n",
            "        [222, 187, 119]],\n",
            "\n",
            "       [[225, 192, 119],\n",
            "        [225, 192, 120],\n",
            "        [224, 191, 119],\n",
            "        ...,\n",
            "        [220, 187, 117],\n",
            "        [221, 187, 117],\n",
            "        [222, 188, 118]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road824.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.9259420000707905, 'inference': 6.052851000049486, 'postprocess': 0.5048709999755374}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[202, 194, 166],\n",
            "        [205, 193, 168],\n",
            "        [204, 191, 165],\n",
            "        ...,\n",
            "        [169, 114,  54],\n",
            "        [169, 114,  54],\n",
            "        [169, 114,  54]],\n",
            "\n",
            "       [[201, 194, 165],\n",
            "        [204, 192, 167],\n",
            "        [204, 191, 164],\n",
            "        ...,\n",
            "        [169, 114,  54],\n",
            "        [169, 114,  54],\n",
            "        [169, 114,  54]],\n",
            "\n",
            "       [[204, 193, 165],\n",
            "        [203, 190, 163],\n",
            "        [202, 189, 162],\n",
            "        ...,\n",
            "        [169, 114,  54],\n",
            "        [170, 115,  54],\n",
            "        [170, 115,  54]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 76, 112, 118],\n",
            "        [ 78, 115, 121],\n",
            "        [ 78, 112, 121],\n",
            "        ...,\n",
            "        [ 12,  10,   2],\n",
            "        [ 12,  10,   3],\n",
            "        [ 13,  11,   4]],\n",
            "\n",
            "       [[ 81, 113, 118],\n",
            "        [ 79, 109, 116],\n",
            "        [ 76, 107, 116],\n",
            "        ...,\n",
            "        [ 12,  10,   2],\n",
            "        [ 12,  10,   2],\n",
            "        [ 12,  10,   2]],\n",
            "\n",
            "       [[ 81, 110, 115],\n",
            "        [ 85, 114, 119],\n",
            "        [ 81, 114, 122],\n",
            "        ...,\n",
            "        [  8,  10,   2],\n",
            "        [  8,  10,   2],\n",
            "        [  9,  10,   2]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road825.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6740169999138743, 'inference': 5.903444000068703, 'postprocess': 0.46696300000803603}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[216, 163,  89],\n",
            "        [218, 162,  91],\n",
            "        [218, 161,  91],\n",
            "        ...,\n",
            "        [225, 171, 101],\n",
            "        [222, 170, 100],\n",
            "        [222, 170, 100]],\n",
            "\n",
            "       [[216, 163,  89],\n",
            "        [218, 162,  91],\n",
            "        [219, 163,  90],\n",
            "        ...,\n",
            "        [224, 170, 100],\n",
            "        [223, 171, 101],\n",
            "        [223, 171, 101]],\n",
            "\n",
            "       [[218, 163,  90],\n",
            "        [218, 162,  91],\n",
            "        [218, 162,  90],\n",
            "        ...,\n",
            "        [224, 170, 101],\n",
            "        [223, 171, 101],\n",
            "        [223, 171, 101]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[235, 201, 131],\n",
            "        [235, 200, 131],\n",
            "        [234, 200, 130],\n",
            "        ...,\n",
            "        [233, 202, 137],\n",
            "        [233, 202, 137],\n",
            "        [232, 202, 136]],\n",
            "\n",
            "       [[235, 201, 131],\n",
            "        [235, 200, 131],\n",
            "        [235, 200, 131],\n",
            "        ...,\n",
            "        [232, 202, 138],\n",
            "        [232, 201, 138],\n",
            "        [232, 202, 138]],\n",
            "\n",
            "       [[233, 200, 129],\n",
            "        [235, 201, 131],\n",
            "        [235, 201, 131],\n",
            "        ...,\n",
            "        [231, 203, 137],\n",
            "        [231, 203, 136],\n",
            "        [231, 203, 137]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road832.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6991989998587087, 'inference': 5.892053000025044, 'postprocess': 0.4725759999928414}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[227, 208, 145],\n",
            "        [229, 207, 147],\n",
            "        [229, 207, 147],\n",
            "        ...,\n",
            "        [236, 217, 159],\n",
            "        [235, 216, 159],\n",
            "        [237, 217, 160]],\n",
            "\n",
            "       [[226, 207, 144],\n",
            "        [229, 207, 147],\n",
            "        [230, 208, 148],\n",
            "        ...,\n",
            "        [236, 217, 159],\n",
            "        [235, 216, 159],\n",
            "        [236, 217, 159]],\n",
            "\n",
            "       [[227, 207, 146],\n",
            "        [228, 207, 148],\n",
            "        [230, 209, 150],\n",
            "        ...,\n",
            "        [236, 217, 159],\n",
            "        [235, 217, 159],\n",
            "        [235, 216, 159]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[100,  90,  65],\n",
            "        [101,  89,  65],\n",
            "        [103,  93,  67],\n",
            "        ...,\n",
            "        [120, 114,  94],\n",
            "        [120, 114,  95],\n",
            "        [117, 112,  92]],\n",
            "\n",
            "       [[113, 104,  79],\n",
            "        [110, 101,  77],\n",
            "        [110, 100,  76],\n",
            "        ...,\n",
            "        [121, 116,  96],\n",
            "        [121, 116,  97],\n",
            "        [122, 117,  97]],\n",
            "\n",
            "       [[120, 116,  91],\n",
            "        [120, 115,  90],\n",
            "        [123, 118,  92],\n",
            "        ...,\n",
            "        [121, 118,  96],\n",
            "        [125, 123, 100],\n",
            "        [135, 132, 110]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road839.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7809559999477642, 'inference': 7.585791000110476, 'postprocess': 0.5321830001321359}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[225, 188, 117],\n",
            "        [227, 188, 118],\n",
            "        [227, 188, 118],\n",
            "        ...,\n",
            "        [233, 199, 132],\n",
            "        [233, 199, 132],\n",
            "        [234, 200, 133]],\n",
            "\n",
            "       [[226, 188, 117],\n",
            "        [227, 188, 118],\n",
            "        [227, 188, 118],\n",
            "        ...,\n",
            "        [233, 199, 132],\n",
            "        [233, 199, 132],\n",
            "        [234, 200, 133]],\n",
            "\n",
            "       [[226, 189, 118],\n",
            "        [227, 188, 118],\n",
            "        [227, 188, 118],\n",
            "        ...,\n",
            "        [234, 200, 133],\n",
            "        [234, 200, 133],\n",
            "        [234, 200, 133]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[237, 232, 180],\n",
            "        [188, 180, 134],\n",
            "        [188, 179, 136],\n",
            "        ...,\n",
            "        [107, 105,  77],\n",
            "        [162, 160, 129],\n",
            "        [191, 190, 155]],\n",
            "\n",
            "       [[226, 222, 176],\n",
            "        [216, 210, 165],\n",
            "        [205, 196, 152],\n",
            "        ...,\n",
            "        [140, 140, 110],\n",
            "        [203, 206, 171],\n",
            "        [195, 195, 156]],\n",
            "\n",
            "       [[152, 149, 104],\n",
            "        [215, 210, 167],\n",
            "        [192, 184, 140],\n",
            "        ...,\n",
            "        [137, 143, 110],\n",
            "        [199, 207, 168],\n",
            "        [204, 208, 165]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road844.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.6929099999742903, 'inference': 5.8925260000251, 'postprocess': 0.4943650001223432}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[196, 190, 147],\n",
            "        [194, 187, 147],\n",
            "        [191, 183, 145],\n",
            "        ...,\n",
            "        [216, 208, 168],\n",
            "        [218, 210, 169],\n",
            "        [218, 210, 169]],\n",
            "\n",
            "       [[204, 197, 153],\n",
            "        [200, 192, 152],\n",
            "        [194, 186, 147],\n",
            "        ...,\n",
            "        [212, 201, 163],\n",
            "        [211, 202, 164],\n",
            "        [215, 206, 167]],\n",
            "\n",
            "       [[209, 198, 156],\n",
            "        [208, 196, 155],\n",
            "        [199, 189, 150],\n",
            "        ...,\n",
            "        [209, 198, 161],\n",
            "        [211, 201, 164],\n",
            "        [212, 205, 167]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[139, 151, 142],\n",
            "        [134, 145, 137],\n",
            "        [125, 135, 128],\n",
            "        ...,\n",
            "        [139, 124,  90],\n",
            "        [136, 121,  86],\n",
            "        [134, 119,  84]],\n",
            "\n",
            "       [[138, 150, 141],\n",
            "        [139, 149, 142],\n",
            "        [136, 146, 139],\n",
            "        ...,\n",
            "        [137, 121,  87],\n",
            "        [137, 121,  87],\n",
            "        [135, 120,  85]],\n",
            "\n",
            "       [[124, 136, 127],\n",
            "        [130, 141, 133],\n",
            "        [133, 145, 136],\n",
            "        ...,\n",
            "        [130, 118,  80],\n",
            "        [134, 122,  85],\n",
            "        [135, 123,  86]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road864.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7470650000177557, 'inference': 5.8946460001152445, 'postprocess': 0.6005970001297101}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[239, 216, 151],\n",
            "        [241, 215, 153],\n",
            "        [242, 217, 154],\n",
            "        ...,\n",
            "        [243, 218, 154],\n",
            "        [243, 218, 154],\n",
            "        [243, 218, 154]],\n",
            "\n",
            "       [[240, 217, 152],\n",
            "        [242, 217, 154],\n",
            "        [242, 217, 154],\n",
            "        ...,\n",
            "        [244, 219, 155],\n",
            "        [243, 219, 154],\n",
            "        [244, 219, 155]],\n",
            "\n",
            "       [[239, 217, 153],\n",
            "        [240, 217, 154],\n",
            "        [242, 217, 154],\n",
            "        ...,\n",
            "        [244, 219, 155],\n",
            "        [243, 219, 154],\n",
            "        [244, 220, 155]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[107, 147, 154],\n",
            "        [112, 152, 161],\n",
            "        [122, 163, 172],\n",
            "        ...,\n",
            "        [102, 139, 145],\n",
            "        [103, 139, 145],\n",
            "        [ 96, 132, 137]],\n",
            "\n",
            "       [[127, 171, 178],\n",
            "        [118, 160, 168],\n",
            "        [120, 161, 169],\n",
            "        ...,\n",
            "        [111, 149, 156],\n",
            "        [107, 143, 149],\n",
            "        [105, 141, 147]],\n",
            "\n",
            "       [[122, 165, 171],\n",
            "        [113, 154, 162],\n",
            "        [108, 149, 156],\n",
            "        ...,\n",
            "        [114, 156, 162],\n",
            "        [110, 149, 154],\n",
            "        [113, 152, 156]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road866.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7386609999903158, 'inference': 5.885708000050727, 'postprocess': 0.45313099985833105}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[234, 209, 142],\n",
            "        [236, 208, 143],\n",
            "        [236, 208, 144],\n",
            "        ...,\n",
            "        [236, 208, 143],\n",
            "        [236, 208, 143],\n",
            "        [236, 208, 143]],\n",
            "\n",
            "       [[235, 208, 143],\n",
            "        [236, 208, 144],\n",
            "        [236, 208, 144],\n",
            "        ...,\n",
            "        [237, 209, 145],\n",
            "        [237, 209, 145],\n",
            "        [237, 209, 145]],\n",
            "\n",
            "       [[236, 210, 143],\n",
            "        [237, 209, 145],\n",
            "        [237, 209, 145],\n",
            "        ...,\n",
            "        [237, 209, 144],\n",
            "        [237, 209, 145],\n",
            "        [237, 209, 145]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 56,  57,  49],\n",
            "        [ 57,  58,  51],\n",
            "        [ 58,  56,  51],\n",
            "        ...,\n",
            "        [ 71,  74,  66],\n",
            "        [ 74,  77,  72],\n",
            "        [ 73,  78,  73]],\n",
            "\n",
            "       [[ 61,  63,  54],\n",
            "        [ 53,  54,  45],\n",
            "        [ 50,  47,  41],\n",
            "        ...,\n",
            "        [ 64,  67,  59],\n",
            "        [ 76,  79,  74],\n",
            "        [ 63,  68,  63]],\n",
            "\n",
            "       [[ 53,  56,  46],\n",
            "        [ 48,  50,  40],\n",
            "        [ 46,  46,  38],\n",
            "        ...,\n",
            "        [ 60,  67,  55],\n",
            "        [ 74,  80,  72],\n",
            "        [ 64,  72,  64]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road868.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.740885000117487, 'inference': 5.894064999893089, 'postprocess': 0.5077159999018477}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[237, 209, 149],\n",
            "        [237, 206, 149],\n",
            "        [233, 203, 146],\n",
            "        ...,\n",
            "        [238, 208, 150],\n",
            "        [238, 207, 150],\n",
            "        [238, 207, 150]],\n",
            "\n",
            "       [[237, 208, 148],\n",
            "        [237, 207, 150],\n",
            "        [236, 207, 149],\n",
            "        ...,\n",
            "        [239, 208, 151],\n",
            "        [238, 207, 150],\n",
            "        [238, 208, 150]],\n",
            "\n",
            "       [[237, 208, 149],\n",
            "        [238, 207, 150],\n",
            "        [239, 209, 151],\n",
            "        ...,\n",
            "        [238, 207, 150],\n",
            "        [238, 208, 150],\n",
            "        [239, 209, 151]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 83,  86,  68],\n",
            "        [ 83,  84,  68],\n",
            "        [ 84,  85,  69],\n",
            "        ...,\n",
            "        [199, 167, 134],\n",
            "        [207, 173, 142],\n",
            "        [211, 177, 144]],\n",
            "\n",
            "       [[ 80,  84,  67],\n",
            "        [ 82,  84,  67],\n",
            "        [ 84,  86,  70],\n",
            "        ...,\n",
            "        [211, 181, 148],\n",
            "        [216, 184, 151],\n",
            "        [215, 182, 150]],\n",
            "\n",
            "       [[ 81,  87,  67],\n",
            "        [ 77,  82,  64],\n",
            "        [ 82,  87,  68],\n",
            "        ...,\n",
            "        [186, 160, 124],\n",
            "        [201, 174, 138],\n",
            "        [191, 163, 128]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road876.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.719954999998663, 'inference': 5.889508999871396, 'postprocess': 0.46063600007073546}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[176, 179, 178],\n",
            "        [176, 179, 178],\n",
            "        [176, 179, 178],\n",
            "        ...,\n",
            "        [173, 175, 174],\n",
            "        [172, 174, 173],\n",
            "        [173, 175, 173]],\n",
            "\n",
            "       [[177, 179, 178],\n",
            "        [177, 179, 178],\n",
            "        [177, 179, 178],\n",
            "        ...,\n",
            "        [174, 176, 175],\n",
            "        [173, 175, 173],\n",
            "        [173, 176, 175]],\n",
            "\n",
            "       [[178, 180, 179],\n",
            "        [178, 180, 179],\n",
            "        [178, 180, 179],\n",
            "        ...,\n",
            "        [173, 176, 174],\n",
            "        [172, 174, 173],\n",
            "        [173, 175, 174]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[215, 215, 210],\n",
            "        [215, 215, 210],\n",
            "        [215, 215, 210],\n",
            "        ...,\n",
            "        [154, 153, 150],\n",
            "        [152, 151, 148],\n",
            "        [150, 149, 146]],\n",
            "\n",
            "       [[215, 215, 210],\n",
            "        [215, 215, 210],\n",
            "        [215, 215, 210],\n",
            "        ...,\n",
            "        [204, 203, 200],\n",
            "        [210, 209, 206],\n",
            "        [214, 213, 210]],\n",
            "\n",
            "       [[214, 214, 210],\n",
            "        [216, 215, 211],\n",
            "        [216, 215, 211],\n",
            "        ...,\n",
            "        [221, 221, 216],\n",
            "        [221, 221, 216],\n",
            "        [220, 220, 216]]], dtype=uint8)\n",
            "orig_shape: (400, 300)\n",
            "path: '/content/yolo_datasets/images/val/road9.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.8674109999210486, 'inference': 5.950245000121868, 'postprocess': 0.46856099993419775}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[152, 192, 178],\n",
            "        [155, 197, 183],\n",
            "        [155, 199, 184],\n",
            "        ...,\n",
            "        [ 18,  34,  26],\n",
            "        [ 17,  34,  25],\n",
            "        [ 17,  34,  23]],\n",
            "\n",
            "       [[147, 188, 174],\n",
            "        [146, 190, 175],\n",
            "        [143, 189, 173],\n",
            "        ...,\n",
            "        [ 17,  34,  25],\n",
            "        [ 17,  33,  24],\n",
            "        [ 17,  33,  23]],\n",
            "\n",
            "       [[130, 176, 161],\n",
            "        [128, 177, 160],\n",
            "        [124, 176, 159],\n",
            "        ...,\n",
            "        [ 16,  33,  24],\n",
            "        [ 15,  32,  23],\n",
            "        [ 15,  31,  22]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 93,  86,  93],\n",
            "        [ 54,  46,  50],\n",
            "        [ 38,  27,  27],\n",
            "        ...,\n",
            "        [  6,  10,  10],\n",
            "        [  8,  10,  11],\n",
            "        [  9,  12,  12]],\n",
            "\n",
            "       [[104,  97, 104],\n",
            "        [ 60,  52,  56],\n",
            "        [ 38,  27,  28],\n",
            "        ...,\n",
            "        [  8,  13,  12],\n",
            "        [ 10,  12,  12],\n",
            "        [ 11,  13,  13]],\n",
            "\n",
            "       [[114, 107, 114],\n",
            "        [ 65,  57,  61],\n",
            "        [ 39,  28,  28],\n",
            "        ...,\n",
            "        [ 11,  15,  15],\n",
            "        [ 12,  15,  15],\n",
            "        [ 14,  16,  16]]], dtype=uint8)\n",
            "orig_shape: (267, 400)\n",
            "path: '/content/yolo_datasets/images/val/road92.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7637020000620396, 'inference': 6.378710000035426, 'postprocess': 0.4431459999523213}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[236, 233, 227],\n",
            "        [236, 233, 227],\n",
            "        [236, 233, 227],\n",
            "        ...,\n",
            "        [246, 245, 244],\n",
            "        [246, 245, 244],\n",
            "        [245, 244, 243]],\n",
            "\n",
            "       [[236, 233, 227],\n",
            "        [236, 233, 227],\n",
            "        [236, 233, 227],\n",
            "        ...,\n",
            "        [246, 244, 244],\n",
            "        [246, 244, 244],\n",
            "        [245, 244, 243]],\n",
            "\n",
            "       [[236, 233, 227],\n",
            "        [236, 233, 227],\n",
            "        [236, 233, 227],\n",
            "        ...,\n",
            "        [246, 244, 244],\n",
            "        [246, 244, 244],\n",
            "        [246, 244, 244]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 46, 123, 121],\n",
            "        [ 46, 123, 121],\n",
            "        [ 35, 108, 105],\n",
            "        ...,\n",
            "        [  0,   8,   1],\n",
            "        [  0,   8,   1],\n",
            "        [  0,  10,   2]],\n",
            "\n",
            "       [[ 50, 134, 133],\n",
            "        [ 51, 134, 133],\n",
            "        [ 36, 112, 112],\n",
            "        ...,\n",
            "        [  0,   8,   1],\n",
            "        [  0,   8,   1],\n",
            "        [  0,  10,   2]],\n",
            "\n",
            "       [[ 47, 136, 135],\n",
            "        [ 52, 140, 140],\n",
            "        [ 36, 113, 113],\n",
            "        ...,\n",
            "        [  0,   8,   1],\n",
            "        [  0,   9,   1],\n",
            "        [  0,  11,   2]]], dtype=uint8)\n",
            "orig_shape: (273, 400)\n",
            "path: '/content/yolo_datasets/images/val/road93.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.67178500009868, 'inference': 5.764042000009795, 'postprocess': 0.46812100003990054}, ultralytics.engine.results.Results object with attributes:\n",
            "\n",
            "boxes: ultralytics.engine.results.Boxes object\n",
            "keypoints: None\n",
            "masks: None\n",
            "names: {0: 'trafficlight', 1: 'stop', 2: 'speedlimit', 3: 'crosswalk'}\n",
            "obb: None\n",
            "orig_img: array([[[240, 222, 213],\n",
            "        [242, 224, 216],\n",
            "        [245, 227, 220],\n",
            "        ...,\n",
            "        [246, 233, 226],\n",
            "        [244, 230, 223],\n",
            "        [242, 228, 221]],\n",
            "\n",
            "       [[239, 221, 212],\n",
            "        [240, 222, 214],\n",
            "        [242, 224, 218],\n",
            "        ...,\n",
            "        [248, 235, 228],\n",
            "        [246, 232, 226],\n",
            "        [245, 231, 224]],\n",
            "\n",
            "       [[236, 219, 210],\n",
            "        [238, 220, 212],\n",
            "        [240, 221, 215],\n",
            "        ...,\n",
            "        [251, 237, 232],\n",
            "        [250, 235, 230],\n",
            "        [248, 234, 229]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[229, 216, 214],\n",
            "        [229, 215, 213],\n",
            "        [226, 213, 209],\n",
            "        ...,\n",
            "        [178, 171, 166],\n",
            "        [178, 171, 165],\n",
            "        [178, 171, 165]],\n",
            "\n",
            "       [[230, 216, 214],\n",
            "        [229, 216, 213],\n",
            "        [227, 213, 210],\n",
            "        ...,\n",
            "        [183, 175, 170],\n",
            "        [184, 177, 171],\n",
            "        [184, 177, 171]],\n",
            "\n",
            "       [[233, 220, 218],\n",
            "        [232, 219, 216],\n",
            "        [230, 217, 214],\n",
            "        ...,\n",
            "        [189, 181, 176],\n",
            "        [188, 181, 175],\n",
            "        [188, 181, 175]]], dtype=uint8)\n",
            "orig_shape: (267, 400)\n",
            "path: '/content/yolo_datasets/images/val/road98.png'\n",
            "probs: None\n",
            "save_dir: '/content/yolo_datasets/runs/detect/predict'\n",
            "speed: {'preprocess': 1.7816760000641807, 'inference': 5.769357999952263, 'postprocess': 0.4670410000926495}]\n"
          ]
        }
      ]
    }
  ]
}